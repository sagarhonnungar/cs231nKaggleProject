{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import keras as k\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [00:53<00:00, 755.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 32, 32, 3)\n",
      "(40479, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "#x_test = []\n",
    "y_train = []\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "#df_test = pd.read_csv('../input/sample_submission.csv')\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "labels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))\n",
    "\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}\n",
    "\n",
    "for f, tags in tqdm(df_train.values[:40479], miniters=1000):\n",
    "    img = cv2.imread('train-jpg/{}.jpg'.format(f))\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    x_train.append(cv2.resize(img, (32, 32)))\n",
    "    y_train.append(targets)\n",
    "\n",
    "#for f, tags in tqdm(df_test.values, miniters=1000):\n",
    "#    img = cv2.imread('../input/test-jpg/{}.jpg'.format(f))\n",
    "#    x_test.append(cv2.resize(img, (32, 32)))\n",
    "    \n",
    "y_train = np.array(y_train, np.uint8)\n",
    "x_train = np.array(x_train, np.float32) / 255.\n",
    "#x_test  = np.array(x_test, np.float32) / 255.\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32383, 32, 32, 3)\n",
      "(32383, 17)\n",
      "(8096, 32, 32, 3)\n",
      "(8096, 17)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train,y_train,test_size=0.2)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(48, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(17, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/1\n",
      "4s - loss: 0.1645 - val_loss: 0.1574\n",
      "F2 score: 0.846135361192\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=[])\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n",
    "model.fit(x = x_train, y= y_train, validation_data=(x_val, y_val),\n",
    "                  batch_size=128,verbose=2, epochs=1,callbacks=callbacks,\n",
    "                  shuffle=True)\n",
    "\n",
    "y_pred = model.predict(x_val, batch_size = 128, verbose=2)\n",
    "print(\"F2 score:\",fbeta_score(y_val, np.array(y_pred)>0.2, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
