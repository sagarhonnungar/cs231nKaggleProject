{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import keras as k\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Input\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score, precision_score \n",
    "from skimage import io,transform\n",
    "\n",
    "import time\n",
    "\n",
    "import os\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=90,\n",
    "    fill_mode='reflect',\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "def multilabelmetrics(y_true,y_pred):\n",
    "    '''y_true and y_pred should be boolean np arrays\n",
    "    of shape num_example x num_classes '''\n",
    "    total = np.sum(y_true,axis = 0)\n",
    "    tp = np.sum(y_true*y_pred,axis=0)\n",
    "    tn = np.sum((1-y_true)*(1-y_pred),axis=0)\n",
    "    fp = np.sum((1-y_true)*y_pred,axis=0)\n",
    "    fn = np.sum(y_true*(1-y_pred),axis=0)\n",
    "    return total,tp,tn,fp,fn\n",
    "\n",
    "def combine_predictions(x,y,y1,y2,thresh,thresh1,thresh2,thresh3):\n",
    "    y_pred = np.zeros((x.shape[0],17),np.uint8)\n",
    "    y_bool = np.array((y > thresh),np.uint8)\n",
    "    y1_bool = np.array((y1 > thresh1),np.uint8)\n",
    "    y2_bool = np.array((y2 > thresh2)*np.tile(y1[:,0]>thresh3,(7,1)).T,np.uint8)\n",
    "    y_pred[:,:7] = y2_bool\n",
    "    y_pred[:,7:13] = y1_bool[:,1:]\n",
    "    y_pred[:,13:] = y_bool\n",
    "    return y_pred\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [09:38<00:00, 69.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 64, 64, 3)\n",
      "(40479, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_train = np.zeros((40479,64,64,3), np.float32)\n",
    "y_train = []\n",
    "\n",
    "df_train = pd.read_csv('train_v2.csv')\n",
    "\n",
    "labels = ['blow_down',\n",
    " 'bare_ground',\n",
    " 'conventional_mine',\n",
    " 'blooming',\n",
    " 'artisinal_mine',\n",
    " 'selective_logging',         \n",
    " 'slash_burn', \n",
    " 'cultivation',\n",
    " 'habitation',\n",
    " 'road',\n",
    " 'agriculture',\n",
    " 'water',\n",
    " 'primary',\n",
    " 'partly_cloudy', \n",
    " 'cloudy',\n",
    " 'clear',\n",
    " 'haze',]\n",
    "\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}\n",
    "\n",
    "i=0\n",
    "\n",
    "for f, tags in tqdm(df_train.values[:40479], miniters=1000):    \n",
    "    img = cv2.imread('train-jpg/{}.jpg'.format(f))\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    x_train[i,:,:,:] = np.array(cv2.resize(img, (64, 64)),np.float32)/255.#139 minimum size for inception\n",
    "    i+=1\n",
    "    y_train.append(targets)\n",
    "  \n",
    "y_train = np.array(y_train, np.uint8)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#subtracting mean\n",
    "train_mean = np.mean(x_train,axis = 0)\n",
    "x_train -= train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36431, 64, 64, 3)\n",
      "(36431, 4)\n",
      "(4048, 64, 64, 3)\n",
      "(4048, 4)\n"
     ]
    }
   ],
   "source": [
    "#weather classifier (last four labels - mutually exclusive)\n",
    "x_train, x_val, y_train_w, y_val_w = train_test_split(x_train,y_train[:,-4:],test_size=0.1)\n",
    "print(x_train.shape)\n",
    "print(y_train_w.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val_w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()#using same architecture for all three models\n",
    "model.add(Conv2D(32, (3, 3), padding = 'same', input_shape=(64, 64, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(48, (3, 3), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(48, (3, 3), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(48, (3, 3), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1024))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "182s - loss: 0.4063 - acc: 0.8605 - val_loss: 0.7732 - val_acc: 0.7922\n",
      "Epoch 2/10\n",
      "170s - loss: 0.3030 - acc: 0.8926 - val_loss: 0.4070 - val_acc: 0.8584\n",
      "Epoch 3/10\n",
      "170s - loss: 0.2789 - acc: 0.8991 - val_loss: 0.3092 - val_acc: 0.8797\n",
      "Epoch 4/10\n",
      "170s - loss: 0.2598 - acc: 0.9049 - val_loss: 0.4549 - val_acc: 0.8449\n",
      "Epoch 5/10\n",
      "170s - loss: 0.2498 - acc: 0.9082 - val_loss: 0.2317 - val_acc: 0.9096\n",
      "Epoch 6/10\n",
      "170s - loss: 0.2399 - acc: 0.9137 - val_loss: 0.2934 - val_acc: 0.8844\n",
      "Epoch 7/10\n",
      "170s - loss: 0.2334 - acc: 0.9172 - val_loss: 0.2912 - val_acc: 0.8854\n",
      "Epoch 8/10\n",
      "170s - loss: 0.2291 - acc: 0.9160 - val_loss: 0.2570 - val_acc: 0.9069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e138ef438>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])    \n",
    "model.fit_generator(datagen.flow(x_train,y_train_w, batch_size = 128), validation_data=(x_val, y_val_w),\n",
    "                  verbose=2, epochs=10, steps_per_epoch=x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.9361251294\n",
      "thresh: 0.1 \tF2 score: 0.93676624553\n",
      "thresh: 0.15 \tF2 score: 0.933676830416\n",
      "thresh: 0.2 \tF2 score: 0.930041878411\n",
      "thresh: 0.25 \tF2 score: 0.925024703557\n",
      "thresh: 0.3 \tF2 score: 0.921495623941\n",
      "thresh: 0.35 \tF2 score: 0.917201910408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_w, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "172s - loss: 0.2214 - acc: 0.9195 - val_loss: 0.2089 - val_acc: 0.9165\n",
      "Epoch 2/10\n",
      "170s - loss: 0.2130 - acc: 0.9226 - val_loss: 0.2198 - val_acc: 0.9190\n",
      "Epoch 3/10\n",
      "170s - loss: 0.2108 - acc: 0.9233 - val_loss: 0.5115 - val_acc: 0.8505\n",
      "Epoch 4/10\n",
      "170s - loss: 0.2103 - acc: 0.9237 - val_loss: 0.1950 - val_acc: 0.9214\n",
      "Epoch 5/10\n",
      "170s - loss: 0.2043 - acc: 0.9255 - val_loss: 0.1999 - val_acc: 0.9224\n",
      "Epoch 6/10\n",
      "170s - loss: 0.2111 - acc: 0.9226 - val_loss: 0.1980 - val_acc: 0.9254\n",
      "Epoch 7/10\n",
      "170s - loss: 0.2034 - acc: 0.9255 - val_loss: 0.2102 - val_acc: 0.9160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e0c0e8cf8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#continue with reduced learning rate\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(lr=0.0005),\n",
    "              metrics=['accuracy']) \n",
    "model.fit_generator(datagen.flow(x_train,y_train_w, batch_size = 128), validation_data=(x_val, y_val_w),\n",
    "                  verbose=2, epochs=10, steps_per_epoch=x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.93630599473\n",
      "thresh: 0.1 \tF2 score: 0.944633152174\n",
      "thresh: 0.15 \tF2 score: 0.945753634952\n",
      "thresh: 0.2 \tF2 score: 0.943787643516\n",
      "thresh: 0.25 \tF2 score: 0.938076416337\n",
      "thresh: 0.3 \tF2 score: 0.932818087709\n",
      "thresh: 0.35 \tF2 score: 0.929718379447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_w, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "172s - loss: 0.1923 - acc: 0.9293 - val_loss: 0.1992 - val_acc: 0.9237\n",
      "Epoch 2/10\n",
      "171s - loss: 0.1914 - acc: 0.9300 - val_loss: 0.1862 - val_acc: 0.9259\n",
      "Epoch 3/10\n",
      "170s - loss: 0.1871 - acc: 0.9312 - val_loss: 0.1868 - val_acc: 0.9242\n",
      "Epoch 4/10\n",
      "170s - loss: 0.1831 - acc: 0.9321 - val_loss: 0.1883 - val_acc: 0.9237\n",
      "Epoch 5/10\n",
      "170s - loss: 0.1849 - acc: 0.9310 - val_loss: 0.1877 - val_acc: 0.9234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8df54bfc50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#continue with reduced learning rate\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(lr=0.0002),\n",
    "              metrics=['accuracy']) \n",
    "model.fit_generator(datagen.flow(x_train,y_train_w, batch_size = 128), validation_data=(x_val, y_val_w),\n",
    "                  verbose=2, epochs=10, steps_per_epoch=x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.941627552701\n",
      "thresh: 0.1 \tF2 score: 0.948378387916\n",
      "thresh: 0.15 \tF2 score: 0.949428289102\n",
      "thresh: 0.2 \tF2 score: 0.948704827781\n",
      "thresh: 0.25 \tF2 score: 0.945740400903\n",
      "thresh: 0.3 \tF2 score: 0.943093591191\n",
      "thresh: 0.35 \tF2 score: 0.938652832675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_w, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "172s - loss: 0.1783 - acc: 0.9336 - val_loss: 0.1822 - val_acc: 0.9318\n",
      "Epoch 2/10\n",
      "171s - loss: 0.1790 - acc: 0.9335 - val_loss: 0.1854 - val_acc: 0.9266\n",
      "Epoch 3/10\n",
      "171s - loss: 0.1748 - acc: 0.9338 - val_loss: 0.1824 - val_acc: 0.9259\n",
      "Epoch 4/10\n",
      "171s - loss: 0.1761 - acc: 0.9342 - val_loss: 0.1840 - val_acc: 0.9274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d952dc6a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#continue with reduced learning rate\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(x_train,y_train_w, batch_size = 128), validation_data=(x_val, y_val_w),\n",
    "                  verbose=2, epochs=10, steps_per_epoch=x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.946557971014\n",
      "thresh: 0.1 \tF2 score: 0.948837168267\n",
      "thresh: 0.15 \tF2 score: 0.951228119706\n",
      "thresh: 0.2 \tF2 score: 0.94972826087\n",
      "thresh: 0.25 \tF2 score: 0.949063617542\n",
      "thresh: 0.3 \tF2 score: 0.943040654997\n",
      "thresh: 0.35 \tF2 score: 0.941576086957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_w, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#continue with reduced learning rate\n",
    "model.compile(optimizer=Adam(lr=0.00005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(x_train,y_train_w, batch_size = 128), validation_data=(x_val, y_val_w),\n",
    "                  verbose=2, epochs=10, steps_per_epoch=x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.945916854884\n",
      "thresh: 0.1 \tF2 score: 0.949700322323\n",
      "thresh: 0.15 \tF2 score: 0.951445746283\n",
      "thresh: 0.2 \tF2 score: 0.949792960663\n",
      "thresh: 0.25 \tF2 score: 0.949422407303\n",
      "thresh: 0.3 \tF2 score: 0.945440429136\n",
      "thresh: 0.35 \tF2 score: 0.939270421607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_w, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save(\"simple_64_weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [00:57<00:00, 701.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 64, 64, 3)\n",
      "(40479, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_val = []\n",
    "x_train = []\n",
    "x_train = np.zeros((40479,64,64,3), np.float32)\n",
    "y_train = []\n",
    "\n",
    "df_train = pd.read_csv('train_v2.csv')\n",
    "\n",
    "labels = ['blow_down',\n",
    " 'bare_ground',\n",
    " 'conventional_mine',\n",
    " 'blooming',\n",
    " 'artisinal_mine',\n",
    " 'selective_logging',         \n",
    " 'slash_burn', \n",
    " 'cultivation',\n",
    " 'habitation',\n",
    " 'road',\n",
    " 'agriculture',\n",
    " 'water',\n",
    " 'primary',\n",
    " 'partly_cloudy', \n",
    " 'cloudy',\n",
    " 'clear',\n",
    " 'haze',]\n",
    "\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}\n",
    "\n",
    "i=0\n",
    "\n",
    "for f, tags in tqdm(df_train.values[:40479], miniters=1000):    \n",
    "    img = cv2.imread('train-jpg/{}.jpg'.format(f))\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    x_train[i,:,:,:] = np.array(cv2.resize(img, (64, 64)),np.float32)/255.#139 minimum size for inception\n",
    "    i+=1\n",
    "    y_train.append(targets)\n",
    "  \n",
    "y_train = np.array(y_train, np.uint8)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train_2 = np.zeros((y_train.shape[0],7))\n",
    "y_train_2[:,1:] = y_train[:,7:13]\n",
    "y_train_2[:,0] = (np.sum(y_train[:,:7],axis=1)>0)\n",
    "y_train_2 = np.array(y_train_2,np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
      "[1 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[100,:])\n",
    "print(y_train_2[100,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36431, 64, 64, 3)\n",
      "(36431, 7)\n",
      "(4048, 64, 64, 3)\n",
      "(4048, 7)\n"
     ]
    }
   ],
   "source": [
    "x_train -= train_mean\n",
    "x_train, x_val, y_train_2, y_val_2 = train_test_split(x_train,y_train_2,test_size=0.1)\n",
    "print(x_train.shape)\n",
    "print(y_train_2.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model for the more common classes + 1 class for others\n",
    "model1 = Sequential()\n",
    "model1.add(Conv2D(32, (3, 3), padding = 'same', input_shape=(64,64,3)))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Conv2D(48, (3, 3), padding = 'same'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Conv2D(48, (3, 3), padding = 'same'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Conv2D(48, (3, 3), padding = 'same'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Conv2D(64, (3, 3), padding = 'same'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Conv2D(64, (3, 3), padding = 'same'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Conv2D(64, (3, 3), padding = 'same'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Conv2D(128, (3, 3), padding = 'same'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Conv2D(128, (3, 3), padding = 'same'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Conv2D(128, (3, 3), padding = 'same'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(2048))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Dense(1024))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Dense(7, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "173s - loss: 0.2903 - acc: 0.8815 - val_loss: 0.4686 - val_acc: 0.8462\n",
      "Epoch 2/10\n",
      "170s - loss: 0.2455 - acc: 0.8993 - val_loss: 0.3574 - val_acc: 0.8333\n",
      "Epoch 3/10\n",
      "171s - loss: 0.2266 - acc: 0.9084 - val_loss: 0.2270 - val_acc: 0.9076\n",
      "Epoch 4/10\n",
      "170s - loss: 0.2182 - acc: 0.9122 - val_loss: 0.3393 - val_acc: 0.8865\n",
      "Epoch 5/10\n",
      "171s - loss: 0.2097 - acc: 0.9159 - val_loss: 0.2161 - val_acc: 0.9103\n",
      "Epoch 6/10\n",
      "171s - loss: 0.2058 - acc: 0.9177 - val_loss: 0.2638 - val_acc: 0.9001\n",
      "Epoch 7/10\n",
      "171s - loss: 0.2021 - acc: 0.9198 - val_loss: 0.1982 - val_acc: 0.9206\n",
      "Epoch 8/10\n",
      "171s - loss: 0.1968 - acc: 0.9216 - val_loss: 0.2804 - val_acc: 0.9082\n",
      "Epoch 9/10\n",
      "171s - loss: 0.1945 - acc: 0.9224 - val_loss: 0.1878 - val_acc: 0.9236\n",
      "Epoch 10/10\n",
      "171s - loss: 0.1916 - acc: 0.9237 - val_loss: 0.5316 - val_acc: 0.8945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8cffe61ba8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model1.fit_generator(datagen.flow(x_train,y_train_2, batch_size = 128), validation_data=(x_val, y_val_2),\n",
    "                  verbose=2, epochs=10, steps_per_epoch=x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.746801426864\n",
      "thresh: 0.1 \tF2 score: 0.763314402342\n",
      "thresh: 0.15 \tF2 score: 0.765838270168\n",
      "thresh: 0.2 \tF2 score: 0.760554254006\n",
      "thresh: 0.25 \tF2 score: 0.755449838243\n",
      "thresh: 0.3 \tF2 score: 0.750917448075\n",
      "thresh: 0.35 \tF2 score: 0.745271867972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_2, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "173s - loss: 0.1857 - acc: 0.9255 - val_loss: 0.1736 - val_acc: 0.9297\n",
      "Epoch 2/10\n",
      "171s - loss: 0.1828 - acc: 0.9275 - val_loss: 0.1717 - val_acc: 0.9309\n",
      "Epoch 3/10\n",
      "171s - loss: 0.1805 - acc: 0.9278 - val_loss: 0.1859 - val_acc: 0.9241\n",
      "Epoch 4/10\n",
      "171s - loss: 0.1793 - acc: 0.9290 - val_loss: 0.1820 - val_acc: 0.9285\n",
      "Epoch 5/10\n",
      "171s - loss: 0.1783 - acc: 0.9290 - val_loss: 0.1695 - val_acc: 0.9315\n",
      "Epoch 6/10\n",
      "171s - loss: 0.1773 - acc: 0.9295 - val_loss: 0.1745 - val_acc: 0.9309\n",
      "Epoch 7/10\n",
      "171s - loss: 0.1752 - acc: 0.9297 - val_loss: 0.1751 - val_acc: 0.9310\n",
      "Epoch 8/10\n",
      "171s - loss: 0.1743 - acc: 0.9304 - val_loss: 0.1967 - val_acc: 0.9174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d8efbfc18>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#continue with reduced learning rate\n",
    "model1.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(lr=0.0005),\n",
    "              metrics=['accuracy']) \n",
    "model1.fit_generator(datagen.flow(x_train,y_train_2, batch_size = 128), validation_data=(x_val, y_val_2),\n",
    "                  verbose=2, epochs=10, steps_per_epoch=x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.843964081591\n",
      "thresh: 0.1 \tF2 score: 0.861422880754\n",
      "thresh: 0.15 \tF2 score: 0.866151013948\n",
      "thresh: 0.2 \tF2 score: 0.867404932153\n",
      "thresh: 0.25 \tF2 score: 0.863969777581\n",
      "thresh: 0.3 \tF2 score: 0.858761041045\n",
      "thresh: 0.35 \tF2 score: 0.853935328968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_2, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "173s - loss: 0.1685 - acc: 0.9330 - val_loss: 0.1595 - val_acc: 0.9353\n",
      "Epoch 2/10\n",
      "171s - loss: 0.1671 - acc: 0.9334 - val_loss: 0.1609 - val_acc: 0.9349\n",
      "Epoch 3/10\n",
      "171s - loss: 0.1655 - acc: 0.9336 - val_loss: 0.1587 - val_acc: 0.9370\n",
      "Epoch 4/10\n",
      "170s - loss: 0.1644 - acc: 0.9347 - val_loss: 0.1629 - val_acc: 0.9356\n",
      "Epoch 5/10\n",
      "170s - loss: 0.1640 - acc: 0.9343 - val_loss: 0.1586 - val_acc: 0.9370\n",
      "Epoch 6/10\n",
      "171s - loss: 0.1640 - acc: 0.9347 - val_loss: 0.1621 - val_acc: 0.9348\n",
      "Epoch 7/10\n",
      "171s - loss: 0.1629 - acc: 0.9350 - val_loss: 0.1610 - val_acc: 0.9348\n",
      "Epoch 8/10\n",
      "171s - loss: 0.1624 - acc: 0.9353 - val_loss: 0.1589 - val_acc: 0.9362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d8d390828>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#continue with reduced learning rate\n",
    "model1.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(lr=0.0002),\n",
    "              metrics=['accuracy']) \n",
    "model1.fit_generator(datagen.flow(x_train,y_train_2, batch_size = 128), validation_data=(x_val, y_val_2),\n",
    "                  verbose=2, epochs=10, steps_per_epoch=x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.844870196703\n",
      "thresh: 0.1 \tF2 score: 0.868406765499\n",
      "thresh: 0.15 \tF2 score: 0.877830717057\n",
      "thresh: 0.2 \tF2 score: 0.88164152037\n",
      "thresh: 0.25 \tF2 score: 0.879562725052\n",
      "thresh: 0.3 \tF2 score: 0.87795035327\n",
      "thresh: 0.35 \tF2 score: 0.87598201732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_2, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "174s - loss: 0.1597 - acc: 0.9363 - val_loss: 0.1564 - val_acc: 0.9371\n",
      "Epoch 2/10\n",
      "171s - loss: 0.1592 - acc: 0.9366 - val_loss: 0.1550 - val_acc: 0.9376\n",
      "Epoch 3/10\n",
      "171s - loss: 0.1585 - acc: 0.9368 - val_loss: 0.1552 - val_acc: 0.9372\n",
      "Epoch 4/10\n",
      "171s - loss: 0.1578 - acc: 0.9369 - val_loss: 0.1565 - val_acc: 0.9377\n",
      "Epoch 5/10\n",
      "171s - loss: 0.1575 - acc: 0.9369 - val_loss: 0.1613 - val_acc: 0.9355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d8b7d4278>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#continue with reduced learning rate\n",
    "model1.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(lr=0.0001),\n",
    "              metrics=['accuracy']) \n",
    "model1.fit_generator(datagen.flow(x_train,y_train_2, batch_size = 128), validation_data=(x_val, y_val_2),\n",
    "                  verbose=2, epochs=10, steps_per_epoch=x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.85135681471\n",
      "thresh: 0.1 \tF2 score: 0.869788309809\n",
      "thresh: 0.15 \tF2 score: 0.876747651648\n",
      "thresh: 0.2 \tF2 score: 0.878477332892\n",
      "thresh: 0.25 \tF2 score: 0.877457525162\n",
      "thresh: 0.3 \tF2 score: 0.874820019708\n",
      "thresh: 0.35 \tF2 score: 0.871043856364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_2, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "173s - loss: 0.1569 - acc: 0.9374 - val_loss: 0.1548 - val_acc: 0.9383\n",
      "Epoch 2/10\n",
      "171s - loss: 0.1558 - acc: 0.9379 - val_loss: 0.1549 - val_acc: 0.9383\n",
      "Epoch 3/10\n",
      "171s - loss: 0.1551 - acc: 0.9381 - val_loss: 0.1542 - val_acc: 0.9380\n",
      "Epoch 4/10\n",
      "171s - loss: 0.1548 - acc: 0.9385 - val_loss: 0.1546 - val_acc: 0.9384\n",
      "Epoch 5/10\n",
      "171s - loss: 0.1544 - acc: 0.9381 - val_loss: 0.1555 - val_acc: 0.9387\n",
      "Epoch 6/10\n",
      "171s - loss: 0.1556 - acc: 0.9379 - val_loss: 0.1546 - val_acc: 0.9377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d89c17c18>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#continue with reduced learning rate\n",
    "model1.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(lr=0.00005),\n",
    "              metrics=['accuracy']) \n",
    "model1.fit_generator(datagen.flow(x_train,y_train_2, batch_size = 128), validation_data=(x_val, y_val_2),\n",
    "                  verbose=2, epochs=10, steps_per_epoch=x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.855414233622\n",
      "thresh: 0.1 \tF2 score: 0.872541230496\n",
      "thresh: 0.15 \tF2 score: 0.879843690059\n",
      "thresh: 0.2 \tF2 score: 0.881157837357\n",
      "thresh: 0.25 \tF2 score: 0.881747899563\n",
      "thresh: 0.3 \tF2 score: 0.879954028018\n",
      "thresh: 0.35 \tF2 score: 0.877321386263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_2, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.855414233622\n",
      "thresh: 0.1 \tF2 score: 0.872541230496\n",
      "thresh: 0.15 \tF2 score: 0.879843690059\n",
      "thresh: 0.2 \tF2 score: 0.881157837357\n",
      "thresh: 0.25 \tF2 score: 0.881747899563\n",
      "thresh: 0.3 \tF2 score: 0.879954028018\n",
      "thresh: 0.35 \tF2 score: 0.877321386263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(x_val,batch_size=128)\n",
    "bestthresh = 0\n",
    "bestF2score = 0\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    F2score = fbeta_score(y_val_2, np.array(y_pred)>thresh, beta=2, average='samples')\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",F2score)\n",
    "    if F2score > bestF2score:\n",
    "        bestthresh = thresh\n",
    "        bestF2score = F2score        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>TP</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>others</th>\n",
       "      <td>101</td>\n",
       "      <td>115</td>\n",
       "      <td>3734</td>\n",
       "      <td>98</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cultivation</th>\n",
       "      <td>142</td>\n",
       "      <td>249</td>\n",
       "      <td>3355</td>\n",
       "      <td>302</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>habitation</th>\n",
       "      <td>57</td>\n",
       "      <td>208</td>\n",
       "      <td>3475</td>\n",
       "      <td>308</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>road</th>\n",
       "      <td>62</td>\n",
       "      <td>310</td>\n",
       "      <td>2946</td>\n",
       "      <td>730</td>\n",
       "      <td>792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agriculture</th>\n",
       "      <td>86</td>\n",
       "      <td>352</td>\n",
       "      <td>2474</td>\n",
       "      <td>1136</td>\n",
       "      <td>1222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>133</td>\n",
       "      <td>255</td>\n",
       "      <td>3050</td>\n",
       "      <td>610</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>primary</th>\n",
       "      <td>11</td>\n",
       "      <td>140</td>\n",
       "      <td>136</td>\n",
       "      <td>3761</td>\n",
       "      <td>3772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              FN   FP    TN    TP  Total\n",
       "others       101  115  3734    98    199\n",
       "cultivation  142  249  3355   302    444\n",
       "habitation    57  208  3475   308    365\n",
       "road          62  310  2946   730    792\n",
       "agriculture   86  352  2474  1136   1222\n",
       "water        133  255  3050   610    743\n",
       "primary       11  140   136  3761   3772"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total,tp,tn,fp,fn = multilabelmetrics(y_val_2,np.array(y_pred)>bestthresh)\n",
    "d = {'Total':total,'TP':tp,'TN':tn,'FP':fp,'FN':fn}\n",
    "pd.DataFrame(d, index=['others']+labels[7:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2180\n"
     ]
    }
   ],
   "source": [
    "num_rare = np.sum(np.sum(y_train[:,:7],axis=1)>0)\n",
    "print(num_rare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1.save(\"simple_64_major\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [00:53<00:00, 756.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2180, 64, 64, 3)\n",
      "(2180, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_val = []\n",
    "x_train = []\n",
    "x_train = np.zeros((num_rare,64,64,3), np.float32)\n",
    "y_train = []\n",
    "\n",
    "df_train = pd.read_csv('train_v2.csv')\n",
    "\n",
    "labels = ['blow_down',\n",
    " 'bare_ground',\n",
    " 'conventional_mine',\n",
    " 'blooming',\n",
    " 'artisinal_mine',\n",
    " 'selective_logging',         \n",
    " 'slash_burn', \n",
    " 'cultivation',\n",
    " 'habitation',\n",
    " 'road',\n",
    " 'agriculture',\n",
    " 'water',\n",
    " 'primary',\n",
    " 'partly_cloudy', \n",
    " 'cloudy',\n",
    " 'clear',\n",
    " 'haze',]\n",
    "\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}\n",
    "\n",
    "i=0\n",
    "\n",
    "for f, tags in tqdm(df_train.values[:40479], miniters=1000):    \n",
    "    img = cv2.imread('train-jpg/{}.jpg'.format(f))\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    if(np.sum(targets[:7])>0):\n",
    "        x_train[i,:,:,:] = np.array(cv2.resize(img, (64, 64)),np.float32)/255.#139 minimum size for inception\n",
    "        i+=1\n",
    "        y_train.append(targets)\n",
    "    \n",
    "y_train = np.array(y_train, np.uint8)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1962, 64, 64, 3)\n",
      "(1962, 7)\n",
      "(218, 64, 64, 3)\n",
      "(218, 7)\n"
     ]
    }
   ],
   "source": [
    "x_train -= train_mean\n",
    "x_train, x_val, y_train_3, y_val_3 = train_test_split(x_train,y_train[:,:7],test_size=0.1)\n",
    "print(x_train.shape)\n",
    "print(y_train_3.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model for the rarer classes\n",
    "from keras.models import load_model\n",
    "model2 = load_model(\"simple_64_major\")\n",
    "for layer in model2.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "model2.layers[-1].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31s - loss: 0.5756 - acc: 0.8271 - val_loss: 0.2896 - val_acc: 0.8847\n",
      "Epoch 2/10\n",
      "27s - loss: 0.2586 - acc: 0.9021 - val_loss: 0.2594 - val_acc: 0.8958\n",
      "Epoch 3/10\n",
      "27s - loss: 0.2296 - acc: 0.9095 - val_loss: 0.2473 - val_acc: 0.9017\n",
      "Epoch 4/10\n",
      "27s - loss: 0.2179 - acc: 0.9129 - val_loss: 0.2423 - val_acc: 0.9017\n",
      "Epoch 5/10\n",
      "27s - loss: 0.2144 - acc: 0.9129 - val_loss: 0.2367 - val_acc: 0.9076\n",
      "Epoch 6/10\n",
      "27s - loss: 0.2088 - acc: 0.9157 - val_loss: 0.2359 - val_acc: 0.9069\n",
      "Epoch 7/10\n",
      "27s - loss: 0.2043 - acc: 0.9175 - val_loss: 0.2283 - val_acc: 0.9076\n",
      "Epoch 8/10\n",
      "27s - loss: 0.2039 - acc: 0.9175 - val_loss: 0.2277 - val_acc: 0.9069\n",
      "Epoch 9/10\n",
      "27s - loss: 0.2000 - acc: 0.9192 - val_loss: 0.2365 - val_acc: 0.9063\n",
      "Epoch 10/10\n",
      "27s - loss: 0.1989 - acc: 0.9200 - val_loss: 0.2310 - val_acc: 0.9102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d873189b0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.fit_generator(datagen.flow(x_train,y_train_3, batch_size = 128), validation_data=(x_val, y_val_3),\n",
    "                  verbose=2, epochs=10, steps_per_epoch=10*x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )#more steps per epoch to compensate for fewer images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.697888948462\n",
      "thresh: 0.1 \tF2 score: 0.732765068774\n",
      "thresh: 0.15 \tF2 score: 0.753088718112\n",
      "thresh: 0.2 \tF2 score: 0.728170466129\n",
      "thresh: 0.25 \tF2 score: 0.710228100136\n",
      "thresh: 0.3 \tF2 score: 0.668450560652\n",
      "thresh: 0.35 \tF2 score: 0.652395514781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_3, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31s - loss: 0.1967 - acc: 0.9202 - val_loss: 0.2275 - val_acc: 0.9076\n",
      "Epoch 2/10\n",
      "27s - loss: 0.1950 - acc: 0.9210 - val_loss: 0.2262 - val_acc: 0.9089\n",
      "Epoch 3/10\n",
      "27s - loss: 0.1951 - acc: 0.9209 - val_loss: 0.2262 - val_acc: 0.9076\n",
      "Epoch 4/10\n",
      "27s - loss: 0.1935 - acc: 0.9207 - val_loss: 0.2293 - val_acc: 0.9096\n",
      "Epoch 5/10\n",
      "27s - loss: 0.1923 - acc: 0.9211 - val_loss: 0.2249 - val_acc: 0.9102\n",
      "Epoch 6/10\n",
      "27s - loss: 0.1924 - acc: 0.9220 - val_loss: 0.2262 - val_acc: 0.9096\n",
      "Epoch 7/10\n",
      "27s - loss: 0.1912 - acc: 0.9218 - val_loss: 0.2251 - val_acc: 0.9076\n",
      "Epoch 8/10\n",
      "27s - loss: 0.1897 - acc: 0.9217 - val_loss: 0.2255 - val_acc: 0.9089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d87167390>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(lr=0.0005),\n",
    "              metrics=['accuracy']) \n",
    "model2.fit_generator(datagen.flow(x_train,y_train_3, batch_size = 128), validation_data=(x_val, y_val_3),\n",
    "                  verbose=2, epochs=10, steps_per_epoch=10*x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.706999549889\n",
      "thresh: 0.1 \tF2 score: 0.737734487734\n",
      "thresh: 0.15 \tF2 score: 0.74578021367\n",
      "thresh: 0.2 \tF2 score: 0.73107963647\n",
      "thresh: 0.25 \tF2 score: 0.700252856216\n",
      "thresh: 0.3 \tF2 score: 0.681156254551\n",
      "thresh: 0.35 \tF2 score: 0.651849424785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_3, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30s - loss: 0.1901 - acc: 0.9223 - val_loss: 0.2267 - val_acc: 0.9056\n",
      "Epoch 2/10\n",
      "27s - loss: 0.1888 - acc: 0.9229 - val_loss: 0.2272 - val_acc: 0.9069\n",
      "Epoch 3/10\n",
      "27s - loss: 0.1882 - acc: 0.9228 - val_loss: 0.2256 - val_acc: 0.9083\n",
      "Epoch 4/10\n",
      "27s - loss: 0.1889 - acc: 0.9222 - val_loss: 0.2252 - val_acc: 0.9083\n",
      "Epoch 5/10\n",
      "27s - loss: 0.1883 - acc: 0.9232 - val_loss: 0.2262 - val_acc: 0.9076\n",
      "Epoch 6/10\n",
      "27s - loss: 0.1885 - acc: 0.9225 - val_loss: 0.2252 - val_acc: 0.9089\n",
      "Epoch 7/10\n",
      "27s - loss: 0.1892 - acc: 0.9222 - val_loss: 0.2243 - val_acc: 0.9083\n",
      "Epoch 8/10\n",
      "27s - loss: 0.1888 - acc: 0.9228 - val_loss: 0.2264 - val_acc: 0.9063\n",
      "Epoch 9/10\n",
      "27s - loss: 0.1893 - acc: 0.9222 - val_loss: 0.2253 - val_acc: 0.9076\n",
      "Epoch 10/10\n",
      "27s - loss: 0.1881 - acc: 0.9228 - val_loss: 0.2247 - val_acc: 0.9089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d86fa5cc0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(lr=0.0002),\n",
    "              metrics=['accuracy']) \n",
    "model2.fit_generator(datagen.flow(x_train,y_train_3, batch_size = 128), validation_data=(x_val, y_val_3),\n",
    "                  verbose=2, epochs=10, steps_per_epoch=10*x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.710094059865\n",
      "thresh: 0.1 \tF2 score: 0.734348729762\n",
      "thresh: 0.15 \tF2 score: 0.756947754081\n",
      "thresh: 0.2 \tF2 score: 0.737960370414\n",
      "thresh: 0.25 \tF2 score: 0.706150628169\n",
      "thresh: 0.3 \tF2 score: 0.67249162662\n",
      "thresh: 0.35 \tF2 score: 0.658511722732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_3, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x7f8d8917aba8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8d8912d828>,\n",
       " <keras.layers.core.Activation at 0x7f8d8913ef28>,\n",
       " <keras.layers.core.Dense at 0x7f8d8913ed30>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f8d890a9048>,\n",
       " <keras.layers.core.Activation at 0x7f8d890b94a8>,\n",
       " <keras.layers.core.Dense at 0x7f8d8904d780>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in model2.layers[-7:]:\n",
    "    layer.trainable = True\n",
    "model2.layers[-7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "34s - loss: 0.1819 - acc: 0.9255 - val_loss: 0.2190 - val_acc: 0.9069\n",
      "Epoch 2/10\n",
      "31s - loss: 0.1706 - acc: 0.9297 - val_loss: 0.2162 - val_acc: 0.9089\n",
      "Epoch 3/10\n",
      "31s - loss: 0.1625 - acc: 0.9327 - val_loss: 0.2115 - val_acc: 0.9115\n",
      "Epoch 4/10\n",
      "31s - loss: 0.1538 - acc: 0.9363 - val_loss: 0.2102 - val_acc: 0.9109\n",
      "Epoch 5/10\n",
      "31s - loss: 0.1472 - acc: 0.9396 - val_loss: 0.2117 - val_acc: 0.9128\n",
      "Epoch 6/10\n",
      "31s - loss: 0.1399 - acc: 0.9425 - val_loss: 0.2106 - val_acc: 0.9135\n",
      "Epoch 7/10\n",
      "31s - loss: 0.1328 - acc: 0.9460 - val_loss: 0.2110 - val_acc: 0.9148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d86a55358>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(lr=0.0001),\n",
    "              metrics=['accuracy']) \n",
    "model2.fit_generator(datagen.flow(x_train,y_train_3, batch_size = 128), validation_data=(x_val, y_val_3),\n",
    "                  verbose=2, epochs=10, steps_per_epoch=10*x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.775207845162\n",
      "thresh: 0.1 \tF2 score: 0.779803275216\n",
      "thresh: 0.15 \tF2 score: 0.772800912136\n",
      "thresh: 0.2 \tF2 score: 0.753842487787\n",
      "thresh: 0.25 \tF2 score: 0.736695261925\n",
      "thresh: 0.3 \tF2 score: 0.726355958007\n",
      "thresh: 0.35 \tF2 score: 0.69730397024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_3, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "34s - loss: 0.1276 - acc: 0.9486 - val_loss: 0.2127 - val_acc: 0.9102\n",
      "Epoch 2/10\n",
      "31s - loss: 0.1261 - acc: 0.9491 - val_loss: 0.2124 - val_acc: 0.9122\n",
      "Epoch 3/10\n",
      "31s - loss: 0.1241 - acc: 0.9500 - val_loss: 0.2140 - val_acc: 0.9109\n",
      "Epoch 4/10\n",
      "31s - loss: 0.1198 - acc: 0.9519 - val_loss: 0.2154 - val_acc: 0.9135\n",
      "Epoch 5/10\n",
      "31s - loss: 0.1166 - acc: 0.9542 - val_loss: 0.2184 - val_acc: 0.9102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d86462908>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(lr=0.00005),\n",
    "              metrics=['accuracy']) \n",
    "model2.fit_generator(datagen.flow(x_train,y_train_3, batch_size = 128), validation_data=(x_val, y_val_3),\n",
    "                  verbose=2, epochs=10, steps_per_epoch=10*x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.774461522168\n",
      "thresh: 0.1 \tF2 score: 0.771036048559\n",
      "thresh: 0.15 \tF2 score: 0.755524610456\n",
      "thresh: 0.2 \tF2 score: 0.751576214306\n",
      "thresh: 0.25 \tF2 score: 0.735603081933\n",
      "thresh: 0.3 \tF2 score: 0.705329838357\n",
      "thresh: 0.35 \tF2 score: 0.689311198486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict(x_val,batch_size=128)\n",
    "bestthresh = 0\n",
    "bestF2score = 0\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    F2score = fbeta_score(y_val_3, np.array(y_pred)>thresh, beta=2, average='samples')\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",F2score)\n",
    "    if F2score > bestF2score:\n",
    "        bestthresh = thresh\n",
    "        bestF2score = F2score    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>TP</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blow_down</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>183</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bare_ground</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>60</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conventional_mine</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>192</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blooming</th>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>155</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artisinal_mine</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>154</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selective_logging</th>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>133</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slash_burn</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>157</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   FN  FP   TN  TP  Total\n",
       "blow_down           2  20  183  13     15\n",
       "bare_ground         1  72   60  85     86\n",
       "conventional_mine   1  17  192   8      9\n",
       "blooming            3  27  155  33     36\n",
       "artisinal_mine      2  30  154  32     34\n",
       "selective_logging   5  57  133  23     28\n",
       "slash_burn          1  46  157  14     15"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total,tp,tn,fp,fn = multilabelmetrics(y_val_3,np.array(y_pred)>bestthresh)\n",
    "d = {'Total':total,'TP':tp,'TN':tn,'FP':fp,'FN':fn}\n",
    "pd.DataFrame(d, index=labels[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2.save(\"simple_64_rare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [00:57<00:00, 705.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 64, 64, 3)\n",
      "(40479, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#F2 score on training set\n",
    "x_val = []\n",
    "x_train = []\n",
    "x_train = np.zeros((40479,64,64,3), np.float32)\n",
    "y_train = []\n",
    "\n",
    "df_train = pd.read_csv('train_v2.csv')\n",
    "\n",
    "labels = ['blow_down',\n",
    " 'bare_ground',\n",
    " 'conventional_mine',\n",
    " 'blooming',\n",
    " 'artisinal_mine',\n",
    " 'selective_logging',         \n",
    " 'slash_burn', \n",
    " 'cultivation',\n",
    " 'habitation',\n",
    " 'road',\n",
    " 'agriculture',\n",
    " 'water',\n",
    " 'primary',\n",
    " 'partly_cloudy', \n",
    " 'cloudy',\n",
    " 'clear',\n",
    " 'haze',]\n",
    "\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}\n",
    "\n",
    "i=0\n",
    "\n",
    "for f, tags in tqdm(df_train.values[:40479], miniters=1000):    \n",
    "    img = cv2.imread('train-jpg/{}.jpg'.format(f))\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    x_train[i,:,:,:] = np.array(cv2.resize(img, (64, 64)),np.float32)/255.#139 minimum size for inception\n",
    "    i+=1\n",
    "    y_train.append(targets)\n",
    "\n",
    "y_train = np.array(y_train, np.uint8)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train -= train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = model.predict(x_train,batch_size=128)\n",
    "y1 = model1.predict(x_train,batch_size=128)\n",
    "y2 = model2.predict(x_train,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 4)\n",
      "(40479, 7)\n",
      "(40479, 7)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(y1.shape)\n",
    "print(y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f2scorelist = []\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3]:\n",
    "    for thresh1 in [0.05,0.1,0.15,0.2,0.25,0.3]:\n",
    "        for thresh2 in [0.05,0.1,0.15,0.2,0.25,0.3]:\n",
    "            for thresh3 in [0.05,0.1,0.15,0.2,0.25,0.3]:\n",
    "                y_pred = combine_predictions(x_train,y,y1,y2,thresh,thresh1,thresh2,thresh3)\n",
    "                f2scorelist.append([thresh,thresh1,thresh2,thresh3,fbeta_score(y_train,y_pred , beta=2, average='samples')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15, 0.25, 0.3, 0.25, 0.92987068926812499], [0.15, 0.25, 0.3, 0.2, 0.92981925261849585], [0.15, 0.25, 0.25, 0.25, 0.92979034269120875], [0.15, 0.25, 0.3, 0.3, 0.92978847562965194], [0.15, 0.25, 0.25, 0.3, 0.92973720344823729], [0.15, 0.2, 0.3, 0.25, 0.92972472618296254], [0.15, 0.25, 0.25, 0.2, 0.92968429441344314], [0.15, 0.2, 0.3, 0.2, 0.92966962429766165], [0.15, 0.25, 0.2, 0.25, 0.92965995026552828], [0.2, 0.25, 0.3, 0.25, 0.92965857834047638]]\n"
     ]
    }
   ],
   "source": [
    "f2scorelist.sort(key=lambda x: x[4],reverse=True)\n",
    "print(f2scorelist[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f2scorelistfiner = []\n",
    "for thresh in [0.12,0.14,0.15,0.16,0.18,0.2,0.22]:\n",
    "    for thresh1 in [0.18,0.2,0.22,0.24,0.25,0.26,0.28]:\n",
    "        for thresh2 in [0.3,0.32,0.34,0.36,0.38,0.4,0.42]:\n",
    "            for thresh3 in [0.18,0.2,0.22,0.24,0.26,0.28,0.3]:\n",
    "                y_pred = combine_predictions(x_train,y,y1,y2,thresh,thresh1,thresh2,thresh3)\n",
    "                f2scorelistfiner.append([thresh,thresh1,thresh2,thresh3,fbeta_score(y_train,y_pred , beta=2, average='samples')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.930067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.930053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.930052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.930051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.930042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.930039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.930036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.930034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.930033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.930028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3         4\n",
       "0  0.18  0.22  0.38  0.22  0.930067\n",
       "1  0.18  0.22  0.42  0.22  0.930053\n",
       "2  0.18  0.24  0.38  0.22  0.930052\n",
       "3  0.18  0.22  0.40  0.22  0.930051\n",
       "4  0.16  0.22  0.38  0.22  0.930042\n",
       "5  0.18  0.22  0.36  0.22  0.930039\n",
       "6  0.18  0.24  0.42  0.22  0.930036\n",
       "7  0.18  0.24  0.40  0.22  0.930034\n",
       "8  0.18  0.25  0.38  0.22  0.930033\n",
       "9  0.16  0.24  0.38  0.22  0.930028"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2scorelistfiner.sort(key=lambda x: x[4],reverse=True)\n",
    "pd.DataFrame(f2scorelistfiner[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.18, 0.22, 0.38, 0.22]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2scorelistfiner[0][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61191/61191 [08:12<00:00, 124.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61191, 64, 64, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Test set\n",
    "x_train = []\n",
    "x_val = []\n",
    "x_test = np.zeros((61191,64,64,3), np.float32)\n",
    "y_train = []\n",
    "\n",
    "df_test = pd.read_csv('sample_submission_v2.csv')\n",
    "\n",
    "i = 0 \n",
    "for f, tags in tqdm(df_test.values, miniters=1000):\n",
    "    img = cv2.imread('test-jpg/{}.jpg'.format(f))\n",
    "    x_test[i,:,:,:] = np.array(cv2.resize(img, (64, 64)),np.float32)/255.#139 minimum size for inception\n",
    "    i+=1\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test -= train_mean\n",
    "\n",
    "y = model.predict(x_test,batch_size=128)\n",
    "y1 = model1.predict(x_test,batch_size=128)\n",
    "y2 = model2.predict(x_test,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61191, 17)\n"
     ]
    }
   ],
   "source": [
    "thresh,thresh1,thresh2,thresh3 = f2scorelistfiner[0][:4]\n",
    "y_pred = combine_predictions(x_test,y,y1,y2,thresh,thresh1,thresh2,thresh3)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels_np = np.array(labels)\n",
    "preds = [' '.join(labels_np[np.array(y_pred[i,:],bool)]) for i in range(y_pred.shape[0])]\n",
    "subm = pd.DataFrame()\n",
    "subm['image_name'] = df_test.values[:,0]\n",
    "subm['tags'] = preds\n",
    "subm.to_csv('submission_64_3net_1.csv', index=False)\n",
    "#test set score:0.92298"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61191, 17)\n"
     ]
    }
   ],
   "source": [
    "thresh,thresh1,thresh2,thresh3 = f2scorelistfiner[1][:4]\n",
    "y_pred = combine_predictions(x_test,y,y1,y2,thresh,thresh1,thresh2,thresh3)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_np = np.array(labels)\n",
    "preds = [' '.join(labels_np[np.array(y_pred[i,:],bool)]) for i in range(y_pred.shape[0])]\n",
    "subm = pd.DataFrame()\n",
    "subm['image_name'] = df_test.values[:,0]\n",
    "subm['tags'] = preds\n",
    "subm.to_csv('submission_64_3net_2.csv', index=False)\n",
    "#test set score:0.92300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61191, 17)\n"
     ]
    }
   ],
   "source": [
    "thresh,thresh1,thresh2,thresh3 = f2scorelistfiner[2][:4]\n",
    "y_pred = combine_predictions(x_test,y,y1,y2,thresh,thresh1,thresh2,thresh3)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_np = np.array(labels)\n",
    "preds = [' '.join(labels_np[np.array(y_pred[i,:],bool)]) for i in range(y_pred.shape[0])]\n",
    "subm = pd.DataFrame()\n",
    "subm['image_name'] = df_test.values[:,0]\n",
    "subm['tags'] = preds\n",
    "subm.to_csv('submission_64_3net_3.csv', index=False)\n",
    "#test set score:0.92285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61191, 17)\n"
     ]
    }
   ],
   "source": [
    "thresh,thresh1,thresh2,thresh3 = f2scorelistfiner[3][:4]\n",
    "y_pred = combine_predictions(x_test,y,y1,y2,thresh,thresh1,thresh2,thresh3)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_np = np.array(labels)\n",
    "preds = [' '.join(labels_np[np.array(y_pred[i,:],bool)]) for i in range(y_pred.shape[0])]\n",
    "subm = pd.DataFrame()\n",
    "subm['image_name'] = df_test.values[:,0]\n",
    "subm['tags'] = preds\n",
    "subm.to_csv('submission_64_3net_4.csv', index=False)\n",
    "#test set score: 0.92300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61191, 17)\n"
     ]
    }
   ],
   "source": [
    "thresh,thresh1,thresh2,thresh3 = f2scorelistfiner[4][:4]\n",
    "y_pred = combine_predictions(x_test,y,y1,y2,thresh,thresh1,thresh2,thresh3)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_np = np.array(labels)\n",
    "preds = [' '.join(labels_np[np.array(y_pred[i,:],bool)]) for i in range(y_pred.shape[0])]\n",
    "subm = pd.DataFrame()\n",
    "subm['image_name'] = df_test.values[:,0]\n",
    "subm['tags'] = preds\n",
    "subm.to_csv('submission_64_3net_5.csv', index=False)\n",
    "#test set score:0.92308"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
