{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import keras as k\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Input\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score, precision_score \n",
    "from skimage import io,transform\n",
    "\n",
    "import time\n",
    "\n",
    "import os\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=90,\n",
    "    fill_mode='reflect',\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "def multilabelmetrics(y_true,y_pred):\n",
    "    '''y_true and y_pred should be boolean np arrays\n",
    "    of shape num_example x num_classes '''\n",
    "    total = np.sum(y_true,axis = 0)\n",
    "    tp = np.sum(y_true*y_pred,axis=0)\n",
    "    tn = np.sum((1-y_true)*(1-y_pred),axis=0)\n",
    "    fp = np.sum((1-y_true)*y_pred,axis=0)\n",
    "    fn = np.sum(y_true*(1-y_pred),axis=0)\n",
    "    return total,tp,tn,fp,fn\n",
    "\n",
    "def combine_predictions(x,y,y1,y2,thresh,thresh1,thresh2,thresh3):\n",
    "    y_pred = np.zeros((x.shape[0],17),np.uint8)\n",
    "    y_bool = np.array((y > thresh),np.uint8)\n",
    "    y1_bool = np.array((y1 > thresh1),np.uint8)\n",
    "    y2_bool = np.array((y2 > thresh2)*np.tile(y1[:,0]>thresh3,(7,1)).T,np.uint8)\n",
    "    y_pred[:,:7] = y2_bool\n",
    "    y_pred[:,7:13] = y1_bool[:,1:]\n",
    "    y_pred[:,13:] = y_bool\n",
    "    return y_pred\n",
    "\n",
    "def combine_predictions_2(x,y,y1,y2,thresh,thresh1,thresh2,thresh3,thresh4):#if cloud > thresh4, \n",
    "    y_pred = np.zeros((x.shape[0],17),np.uint8)\n",
    "    y_bool = np.array((y > thresh),np.uint8)\n",
    "    y1_bool = np.array((y1 > thresh1),np.uint8)\n",
    "    y2_bool = np.array((y2 > thresh2)*np.tile(y1[:,0]>thresh3,(7,1)).T,np.uint8)\n",
    "    y_pred[:,:7] = y2_bool\n",
    "    y_pred[:,7:13] = y1_bool[:,1:]\n",
    "    y_pred[:,13:] = y_bool\n",
    "    y_pred[((np.nonzero(y[:,1]>thresh4))[0]),:] = 0\n",
    "    y_pred[((np.nonzero(y[:,1]>thresh4))[0]),14] = 1\n",
    "    return y_pred\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [00:53<00:00, 760.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 32, 32, 3)\n",
      "(40479, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_train = np.zeros((40479,32,32,3), np.float32)\n",
    "y_train = []\n",
    "\n",
    "df_train = pd.read_csv('train_v2.csv')\n",
    "\n",
    "labels = ['blow_down',\n",
    " 'bare_ground',\n",
    " 'conventional_mine',\n",
    " 'blooming',\n",
    " 'artisinal_mine',\n",
    " 'selective_logging',         \n",
    " 'slash_burn', \n",
    " 'cultivation',\n",
    " 'habitation',\n",
    " 'road',\n",
    " 'water',\n",
    " 'haze',\n",
    " 'partly_cloudy', \n",
    " 'cloudy',\n",
    " 'agriculture',\n",
    " 'clear',\n",
    " 'primary',]\n",
    "\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}\n",
    "\n",
    "i=0\n",
    "\n",
    "for f, tags in tqdm(df_train.values[:40479], miniters=1000):    \n",
    "    img = cv2.imread('train-jpg/{}.jpg'.format(f))\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    x_train[i,:,:,:] = np.array(cv2.resize(img, (32, 32)),np.float32)/255.#139 minimum size for inception\n",
    "    i+=1\n",
    "    y_train.append(targets)\n",
    "  \n",
    "y_train = np.array(y_train, np.uint8)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#subtracting mean\n",
    "train_mean = np.mean(x_train,axis = 0)\n",
    "x_train -= train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36431, 32, 32, 3)\n",
      "(36431, 4)\n",
      "(4048, 32, 32, 3)\n",
      "(4048, 4)\n"
     ]
    }
   ],
   "source": [
    "#last three labels +others\n",
    "y_train_1 = np.zeros((y_train.shape[0],4))\n",
    "y_train_1[:,1:] = y_train[:,-3:]\n",
    "y_train_1[:,0] = (np.sum(y_train[:,:-3],axis=1)>0)\n",
    "y_train_1 = np.array(y_train_1,np.uint8)\n",
    "x_train, x_val, y_train_1, y_val_1 = train_test_split(x_train,y_train_1,test_size=0.1)\n",
    "print(x_train.shape)\n",
    "print(y_train_1.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()#using same architecture for all three models\n",
    "model.add(Conv2D(32, (3, 3), padding = 'same', input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(48, (3, 3), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(48, (3, 3), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(48, (3, 3), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1024))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(4, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "285/284 [==============================] - 52s - loss: 0.2859 - acc: 0.8812 - val_loss: 0.7289 - val_acc: 0.7474\n",
      "Epoch 2/10\n",
      "285/284 [==============================] - 50s - loss: 0.2363 - acc: 0.9038 - val_loss: 0.2709 - val_acc: 0.8896\n",
      "Epoch 3/10\n",
      "285/284 [==============================] - 50s - loss: 0.2200 - acc: 0.9118 - val_loss: 0.2151 - val_acc: 0.9130\n",
      "Epoch 4/10\n",
      "285/284 [==============================] - 50s - loss: 0.2133 - acc: 0.9139 - val_loss: 0.2211 - val_acc: 0.9098\n",
      "Epoch 5/10\n",
      "285/284 [==============================] - 50s - loss: 0.2053 - acc: 0.9174 - val_loss: 0.2018 - val_acc: 0.9216\n",
      "Epoch 6/10\n",
      "285/284 [==============================] - 50s - loss: 0.2030 - acc: 0.9184 - val_loss: 0.2196 - val_acc: 0.9156\n",
      "Epoch 7/10\n",
      "285/284 [==============================] - 50s - loss: 0.1997 - acc: 0.9192 - val_loss: 0.2430 - val_acc: 0.8991\n",
      "Epoch 8/10\n",
      "285/284 [==============================] - 50s - loss: 0.1961 - acc: 0.9219 - val_loss: 0.1971 - val_acc: 0.9172\n",
      "Epoch 9/10\n",
      "285/284 [==============================] - 50s - loss: 0.1953 - acc: 0.9218 - val_loss: 0.2020 - val_acc: 0.9197\n",
      "Epoch 10/10\n",
      "285/284 [==============================] - 50s - loss: 0.1948 - acc: 0.9221 - val_loss: 0.1899 - val_acc: 0.9232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7bad78860>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])    \n",
    "model.fit_generator(datagen.flow(x_train,y_train_1, batch_size = 128), validation_data=(x_val, y_val_1),\n",
    "                  epochs=10, steps_per_epoch=x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.939388471976\n",
      "thresh: 0.1 \tF2 score: 0.950734733453\n",
      "thresh: 0.15 \tF2 score: 0.955401082536\n",
      "thresh: 0.2 \tF2 score: 0.957815327463\n",
      "thresh: 0.25 \tF2 score: 0.957823675256\n",
      "thresh: 0.3 \tF2 score: 0.958387797976\n",
      "thresh: 0.35 \tF2 score: 0.957659220208\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_1, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "285/284 [==============================] - 52s - loss: 0.1877 - acc: 0.9243 - val_loss: 0.1852 - val_acc: 0.9262\n",
      "Epoch 2/10\n",
      "285/284 [==============================] - 51s - loss: 0.1861 - acc: 0.9253 - val_loss: 0.1798 - val_acc: 0.9262\n",
      "Epoch 3/10\n",
      "285/284 [==============================] - 50s - loss: 0.1838 - acc: 0.9263 - val_loss: 0.1744 - val_acc: 0.9296\n",
      "Epoch 4/10\n",
      "285/284 [==============================] - 51s - loss: 0.1831 - acc: 0.9262 - val_loss: 0.1745 - val_acc: 0.9280\n",
      "Epoch 5/10\n",
      "285/284 [==============================] - 50s - loss: 0.1815 - acc: 0.9269 - val_loss: 0.1724 - val_acc: 0.9294\n",
      "Epoch 6/10\n",
      "285/284 [==============================] - 50s - loss: 0.1806 - acc: 0.9273 - val_loss: 0.1761 - val_acc: 0.9295\n",
      "Epoch 7/10\n",
      "285/284 [==============================] - 50s - loss: 0.1789 - acc: 0.9275 - val_loss: 0.1840 - val_acc: 0.9258\n",
      "Epoch 8/10\n",
      "285/284 [==============================] - 50s - loss: 0.1782 - acc: 0.9283 - val_loss: 0.1738 - val_acc: 0.9290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7b81bbb00>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#continue with reduced learning rate\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(lr=0.0005),\n",
    "              metrics=['accuracy']) \n",
    "model.fit_generator(datagen.flow(x_train,y_train_1, batch_size = 128), validation_data=(x_val, y_val_1),\n",
    "                  epochs=10, steps_per_epoch=x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.951457165947\n",
      "thresh: 0.1 \tF2 score: 0.959909379277\n",
      "thresh: 0.15 \tF2 score: 0.961930620102\n",
      "thresh: 0.2 \tF2 score: 0.962087778826\n",
      "thresh: 0.25 \tF2 score: 0.960786525338\n",
      "thresh: 0.3 \tF2 score: 0.959661004316\n",
      "thresh: 0.35 \tF2 score: 0.957541742522\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_1, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "285/284 [==============================] - 53s - loss: 0.1720 - acc: 0.9309 - val_loss: 0.1666 - val_acc: 0.9313\n",
      "Epoch 2/10\n",
      "285/284 [==============================] - 50s - loss: 0.1711 - acc: 0.9310 - val_loss: 0.1675 - val_acc: 0.9315\n",
      "Epoch 3/10\n",
      "285/284 [==============================] - 50s - loss: 0.1706 - acc: 0.9305 - val_loss: 0.1654 - val_acc: 0.9329\n",
      "Epoch 4/10\n",
      "285/284 [==============================] - 50s - loss: 0.1699 - acc: 0.9306 - val_loss: 0.1642 - val_acc: 0.9316\n",
      "Epoch 5/10\n",
      "285/284 [==============================] - 51s - loss: 0.1694 - acc: 0.9315 - val_loss: 0.1668 - val_acc: 0.9320\n",
      "Epoch 6/10\n",
      "285/284 [==============================] - 50s - loss: 0.1690 - acc: 0.9320 - val_loss: 0.1655 - val_acc: 0.9316\n",
      "Epoch 7/10\n",
      "285/284 [==============================] - 50s - loss: 0.1679 - acc: 0.9318 - val_loss: 0.1640 - val_acc: 0.9322\n",
      "Epoch 8/10\n",
      "285/284 [==============================] - 50s - loss: 0.1675 - acc: 0.9320 - val_loss: 0.1656 - val_acc: 0.9329\n",
      "Epoch 9/10\n",
      "285/284 [==============================] - 50s - loss: 0.1666 - acc: 0.9326 - val_loss: 0.1699 - val_acc: 0.9297\n",
      "Epoch 10/10\n",
      "285/284 [==============================] - 50s - loss: 0.1671 - acc: 0.9321 - val_loss: 0.1656 - val_acc: 0.9324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7b5afeeb8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#continue with reduced learning rate\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(lr=0.0002),\n",
    "              metrics=['accuracy']) \n",
    "model.fit_generator(datagen.flow(x_train,y_train_1, batch_size = 128), validation_data=(x_val, y_val_1),\n",
    "                  epochs=10, steps_per_epoch=x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.951512547839\n",
      "thresh: 0.1 \tF2 score: 0.959727880378\n",
      "thresh: 0.15 \tF2 score: 0.963224139882\n",
      "thresh: 0.2 \tF2 score: 0.964286186937\n",
      "thresh: 0.25 \tF2 score: 0.963844261647\n",
      "thresh: 0.3 \tF2 score: 0.963093951943\n",
      "thresh: 0.35 \tF2 score: 0.960863067745\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_1, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "285/284 [==============================] - 53s - loss: 0.1657 - acc: 0.9324 - val_loss: 0.1623 - val_acc: 0.9334\n",
      "Epoch 2/10\n",
      "285/284 [==============================] - 50s - loss: 0.1635 - acc: 0.9334 - val_loss: 0.1637 - val_acc: 0.9331\n",
      "Epoch 3/10\n",
      "285/284 [==============================] - 50s - loss: 0.1624 - acc: 0.9342 - val_loss: 0.1604 - val_acc: 0.9350\n",
      "Epoch 4/10\n",
      "285/284 [==============================] - 50s - loss: 0.1622 - acc: 0.9345 - val_loss: 0.1600 - val_acc: 0.9346\n",
      "Epoch 5/10\n",
      "285/284 [==============================] - 50s - loss: 0.1635 - acc: 0.9334 - val_loss: 0.1610 - val_acc: 0.9352\n",
      "Epoch 6/10\n",
      "285/284 [==============================] - 50s - loss: 0.1626 - acc: 0.9334 - val_loss: 0.1617 - val_acc: 0.9347\n",
      "Epoch 7/10\n",
      "285/284 [==============================] - 50s - loss: 0.1620 - acc: 0.9343 - val_loss: 0.1606 - val_acc: 0.9345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7b49cb048>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#continue with reduced learning rate\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(x_train,y_train_1, batch_size = 128), validation_data=(x_val, y_val_1),\n",
    "                  epochs=10, steps_per_epoch=x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.95678010994\n",
      "thresh: 0.1 \tF2 score: 0.963187576356\n",
      "thresh: 0.15 \tF2 score: 0.963757794741\n",
      "thresh: 0.2 \tF2 score: 0.964217239959\n",
      "thresh: 0.25 \tF2 score: 0.963596096492\n",
      "thresh: 0.3 \tF2 score: 0.963189944752\n",
      "thresh: 0.35 \tF2 score: 0.96209597896\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_1, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "285/284 [==============================] - 53s - loss: 0.1604 - acc: 0.9346 - val_loss: 0.1602 - val_acc: 0.9346\n",
      "Epoch 2/10\n",
      "285/284 [==============================] - 50s - loss: 0.1605 - acc: 0.9345 - val_loss: 0.1612 - val_acc: 0.9335\n",
      "Epoch 3/10\n",
      "285/284 [==============================] - 51s - loss: 0.1606 - acc: 0.9342 - val_loss: 0.1593 - val_acc: 0.9352\n",
      "Epoch 4/10\n",
      "285/284 [==============================] - 51s - loss: 0.1602 - acc: 0.9349 - val_loss: 0.1599 - val_acc: 0.9337\n",
      "Epoch 5/10\n",
      "285/284 [==============================] - 51s - loss: 0.1597 - acc: 0.9349 - val_loss: 0.1592 - val_acc: 0.9348\n",
      "Epoch 6/10\n",
      "285/284 [==============================] - 50s - loss: 0.1603 - acc: 0.9346 - val_loss: 0.1612 - val_acc: 0.9341\n",
      "Epoch 7/10\n",
      "285/284 [==============================] - 50s - loss: 0.1591 - acc: 0.9349 - val_loss: 0.1606 - val_acc: 0.9349\n",
      "Epoch 8/10\n",
      "285/284 [==============================] - 50s - loss: 0.1586 - acc: 0.9358 - val_loss: 0.1598 - val_acc: 0.9349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7b2e0bdd8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#continue with reduced learning rate\n",
    "model.compile(optimizer=Adam(lr=0.00005), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(x_train,y_train_1, batch_size = 128), validation_data=(x_val, y_val_1),\n",
    "                  epochs=10, steps_per_epoch=x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.955327973884\n",
      "thresh: 0.1 \tF2 score: 0.962399867147\n",
      "thresh: 0.15 \tF2 score: 0.964426179859\n",
      "thresh: 0.2 \tF2 score: 0.965192494934\n",
      "thresh: 0.25 \tF2 score: 0.965051124649\n",
      "thresh: 0.3 \tF2 score: 0.964377899819\n",
      "thresh: 0.35 \tF2 score: 0.962920904117\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_1, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save(\"32_net1\")\n",
    "model.save_weights(\"32_net1_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25171\n"
     ]
    }
   ],
   "source": [
    "num_2 = np.sum(np.sum(y_train[:,:-3],axis=1)>0)\n",
    "print(num_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [00:54<00:00, 738.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25171, 32, 32, 3)\n",
      "(25171, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_val = []\n",
    "x_train = []\n",
    "x_train = np.zeros((num_2,32,32,3), np.float32)\n",
    "y_train = []\n",
    "\n",
    "df_train = pd.read_csv('train_v2.csv')\n",
    "\n",
    "labels = ['blow_down',\n",
    " 'bare_ground',\n",
    " 'conventional_mine',\n",
    " 'blooming',\n",
    " 'artisinal_mine',\n",
    " 'selective_logging',         \n",
    " 'slash_burn', \n",
    " 'cultivation',\n",
    " 'habitation',\n",
    " 'road',\n",
    " 'water',\n",
    " 'haze',\n",
    " 'partly_cloudy', \n",
    " 'cloudy',\n",
    " 'agriculture',\n",
    " 'clear',\n",
    " 'primary',]\n",
    "\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}\n",
    "\n",
    "i=0\n",
    "\n",
    "for f, tags in tqdm(df_train.values[:40479], miniters=1000):    \n",
    "    img = cv2.imread('train-jpg/{}.jpg'.format(f))\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    if(np.sum(targets[:-3])>0):\n",
    "        x_train[i,:,:,:] = np.array(cv2.resize(img, (32, 32)),np.float32)/255.#139 minimum size for inception\n",
    "        i+=1\n",
    "        y_train.append(targets)\n",
    "    \n",
    "y_train = np.array(y_train, np.uint8)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train_2 = np.zeros((y_train.shape[0],8))\n",
    "y_train_2[:,1:] = y_train[:,-10:-3]\n",
    "y_train_2[:,0] = (np.sum(y_train[:,:-10],axis=1)>0)\n",
    "y_train_2 = np.array(y_train_2,np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1]\n",
      "[0 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[100,:])\n",
    "print(y_train_2[100,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22653, 32, 32, 3)\n",
      "(22653, 8)\n",
      "(2518, 32, 32, 3)\n",
      "(2518, 8)\n"
     ]
    }
   ],
   "source": [
    "x_train -= train_mean\n",
    "x_train, x_val, y_train_2, y_val_2 = train_test_split(x_train,y_train_2,test_size=0.1)\n",
    "print(x_train.shape)\n",
    "print(y_train_2.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model1\n",
    "from keras.models import load_model\n",
    "model1 = load_model(\"32_net1\")\n",
    "model1.pop()\n",
    "model1.add(Dense(8, activation='sigmoid'))\n",
    "\n",
    "for layer in model1.layers[:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "177/176 [==============================] - 14s - loss: 0.3110 - acc: 0.8675 - val_loss: 0.2641 - val_acc: 0.8878\n",
      "Epoch 2/10\n",
      "177/176 [==============================] - 11s - loss: 0.2678 - acc: 0.8859 - val_loss: 0.2572 - val_acc: 0.8904\n",
      "Epoch 3/10\n",
      "177/176 [==============================] - 11s - loss: 0.2625 - acc: 0.8875 - val_loss: 0.2549 - val_acc: 0.8919\n",
      "Epoch 4/10\n",
      "177/176 [==============================] - 11s - loss: 0.2600 - acc: 0.8891 - val_loss: 0.2525 - val_acc: 0.8939\n",
      "Epoch 5/10\n",
      "177/176 [==============================] - 11s - loss: 0.2580 - acc: 0.8897 - val_loss: 0.2509 - val_acc: 0.8933\n",
      "Epoch 6/10\n",
      "177/176 [==============================] - 11s - loss: 0.2580 - acc: 0.8895 - val_loss: 0.2513 - val_acc: 0.8908\n",
      "Epoch 7/10\n",
      "177/176 [==============================] - 11s - loss: 0.2557 - acc: 0.8906 - val_loss: 0.2485 - val_acc: 0.8944\n",
      "Epoch 8/10\n",
      "177/176 [==============================] - 11s - loss: 0.2554 - acc: 0.8906 - val_loss: 0.2495 - val_acc: 0.8927\n",
      "Epoch 9/10\n",
      "177/176 [==============================] - 11s - loss: 0.2540 - acc: 0.8907 - val_loss: 0.2466 - val_acc: 0.8946\n",
      "Epoch 10/10\n",
      "177/176 [==============================] - 11s - loss: 0.2547 - acc: 0.8911 - val_loss: 0.2513 - val_acc: 0.8929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7b0694eb8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model1.fit_generator(datagen.flow(x_train,y_train_2, batch_size = 128), validation_data=(x_val, y_val_2),\n",
    "                   epochs=10, steps_per_epoch=x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.739930490467\n",
      "thresh: 0.1 \tF2 score: 0.770330021322\n",
      "thresh: 0.15 \tF2 score: 0.779769878305\n",
      "thresh: 0.2 \tF2 score: 0.775405938237\n",
      "thresh: 0.25 \tF2 score: 0.761122709817\n",
      "thresh: 0.3 \tF2 score: 0.74102797253\n",
      "thresh: 0.35 \tF2 score: 0.717149168044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_2, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "177/176 [==============================] - 35s - loss: 0.2504 - acc: 0.8946 - val_loss: 0.3112 - val_acc: 0.8720\n",
      "Epoch 2/10\n",
      "177/176 [==============================] - 31s - loss: 0.2405 - acc: 0.9001 - val_loss: 0.2506 - val_acc: 0.8967\n",
      "Epoch 3/10\n",
      "177/176 [==============================] - 31s - loss: 0.2346 - acc: 0.9027 - val_loss: 0.2676 - val_acc: 0.8909\n",
      "Epoch 4/10\n",
      "177/176 [==============================] - 31s - loss: 0.2319 - acc: 0.9046 - val_loss: 0.2432 - val_acc: 0.9038\n",
      "Epoch 5/10\n",
      "177/176 [==============================] - 31s - loss: 0.2288 - acc: 0.9052 - val_loss: 0.2386 - val_acc: 0.9016\n",
      "Epoch 6/10\n",
      "177/176 [==============================] - 31s - loss: 0.2276 - acc: 0.9058 - val_loss: 0.2354 - val_acc: 0.9029\n",
      "Epoch 7/10\n",
      "177/176 [==============================] - 31s - loss: 0.2249 - acc: 0.9066 - val_loss: 0.2250 - val_acc: 0.9075\n",
      "Epoch 8/10\n",
      "177/176 [==============================] - 31s - loss: 0.2231 - acc: 0.9083 - val_loss: 0.2446 - val_acc: 0.8969\n",
      "Epoch 9/10\n",
      "177/176 [==============================] - 31s - loss: 0.2225 - acc: 0.9084 - val_loss: 0.2287 - val_acc: 0.9058\n",
      "Epoch 10/10\n",
      "177/176 [==============================] - 31s - loss: 0.2204 - acc: 0.9095 - val_loss: 0.2263 - val_acc: 0.9076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7ae83ef98>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in model1.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "model1.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy']) \n",
    "model1.fit_generator(datagen.flow(x_train,y_train_2, batch_size = 128), validation_data=(x_val, y_val_2),\n",
    "                   epochs=10, steps_per_epoch=x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.763049753326\n",
      "thresh: 0.1 \tF2 score: 0.798936952927\n",
      "thresh: 0.15 \tF2 score: 0.8024707007\n",
      "thresh: 0.2 \tF2 score: 0.799249070495\n",
      "thresh: 0.25 \tF2 score: 0.787243646363\n",
      "thresh: 0.3 \tF2 score: 0.777298645551\n",
      "thresh: 0.35 \tF2 score: 0.766756612624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_2, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "177/176 [==============================] - 34s - loss: 0.2131 - acc: 0.9126 - val_loss: 0.2130 - val_acc: 0.9145\n",
      "Epoch 2/10\n",
      "177/176 [==============================] - 31s - loss: 0.2110 - acc: 0.9139 - val_loss: 0.2218 - val_acc: 0.9074\n",
      "Epoch 3/10\n",
      "177/176 [==============================] - 31s - loss: 0.2100 - acc: 0.9138 - val_loss: 0.2084 - val_acc: 0.9153\n",
      "Epoch 4/10\n",
      "177/176 [==============================] - 31s - loss: 0.2086 - acc: 0.9144 - val_loss: 0.2073 - val_acc: 0.9175\n",
      "Epoch 5/10\n",
      "177/176 [==============================] - 31s - loss: 0.2063 - acc: 0.9151 - val_loss: 0.2082 - val_acc: 0.9154\n",
      "Epoch 6/10\n",
      "177/176 [==============================] - 31s - loss: 0.2068 - acc: 0.9152 - val_loss: 0.2089 - val_acc: 0.9142\n",
      "Epoch 7/10\n",
      "177/176 [==============================] - 31s - loss: 0.2056 - acc: 0.9159 - val_loss: 0.2156 - val_acc: 0.9128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7acc044e0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#continue with reduced learning rate\n",
    "model1.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(lr=0.0005),\n",
    "              metrics=['accuracy']) \n",
    "model1.fit_generator(datagen.flow(x_train,y_train_2, batch_size = 128), validation_data=(x_val, y_val_2),\n",
    "                   epochs=10, steps_per_epoch=x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.770638243595\n",
      "thresh: 0.1 \tF2 score: 0.799896182667\n",
      "thresh: 0.15 \tF2 score: 0.80807109544\n",
      "thresh: 0.2 \tF2 score: 0.80575773335\n",
      "thresh: 0.25 \tF2 score: 0.79474363349\n",
      "thresh: 0.3 \tF2 score: 0.784058100791\n",
      "thresh: 0.35 \tF2 score: 0.773709917281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_2, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "177/176 [==============================] - 35s - loss: 0.2009 - acc: 0.9176 - val_loss: 0.2040 - val_acc: 0.9179\n",
      "Epoch 2/10\n",
      "177/176 [==============================] - 31s - loss: 0.1985 - acc: 0.9186 - val_loss: 0.1996 - val_acc: 0.9198\n",
      "Epoch 3/10\n",
      "177/176 [==============================] - 31s - loss: 0.1980 - acc: 0.9183 - val_loss: 0.1982 - val_acc: 0.9192\n",
      "Epoch 4/10\n",
      "177/176 [==============================] - 31s - loss: 0.1972 - acc: 0.9191 - val_loss: 0.2010 - val_acc: 0.9193\n",
      "Epoch 5/10\n",
      "177/176 [==============================] - 31s - loss: 0.1975 - acc: 0.9190 - val_loss: 0.2010 - val_acc: 0.9182\n",
      "Epoch 6/10\n",
      "177/176 [==============================] - 31s - loss: 0.1968 - acc: 0.9196 - val_loss: 0.2008 - val_acc: 0.9190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7a9b48f98>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#continue with reduced learning rate\n",
    "model1.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(lr=0.0002),\n",
    "              metrics=['accuracy']) \n",
    "model1.fit_generator(datagen.flow(x_train,y_train_2, batch_size = 128), validation_data=(x_val, y_val_2),\n",
    "                   epochs=10, steps_per_epoch=x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.779047528093\n",
      "thresh: 0.1 \tF2 score: 0.809476769439\n",
      "thresh: 0.15 \tF2 score: 0.820844177521\n",
      "thresh: 0.2 \tF2 score: 0.820803629605\n",
      "thresh: 0.25 \tF2 score: 0.813905763879\n",
      "thresh: 0.3 \tF2 score: 0.805927528302\n",
      "thresh: 0.35 \tF2 score: 0.792862623304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_2, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "177/176 [==============================] - 35s - loss: 0.1944 - acc: 0.9205 - val_loss: 0.1979 - val_acc: 0.9202\n",
      "Epoch 2/10\n",
      "177/176 [==============================] - 31s - loss: 0.1933 - acc: 0.9207 - val_loss: 0.1993 - val_acc: 0.9185\n",
      "Epoch 3/10\n",
      "177/176 [==============================] - 31s - loss: 0.1931 - acc: 0.9209 - val_loss: 0.1969 - val_acc: 0.9194\n",
      "Epoch 4/10\n",
      "177/176 [==============================] - 31s - loss: 0.1920 - acc: 0.9211 - val_loss: 0.1987 - val_acc: 0.9187\n",
      "Epoch 5/10\n",
      "177/176 [==============================] - 31s - loss: 0.1931 - acc: 0.9206 - val_loss: 0.1990 - val_acc: 0.9189\n",
      "Epoch 6/10\n",
      "177/176 [==============================] - 31s - loss: 0.1929 - acc: 0.9207 - val_loss: 0.1978 - val_acc: 0.9208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7a949ba90>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#continue with reduced learning rate\n",
    "model1.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(lr=0.0001),\n",
    "              metrics=['accuracy']) \n",
    "model1.fit_generator(datagen.flow(x_train,y_train_2, batch_size = 128), validation_data=(x_val, y_val_2),\n",
    "                  epochs=10, steps_per_epoch=x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.786889746228\n",
      "thresh: 0.1 \tF2 score: 0.815301058606\n",
      "thresh: 0.15 \tF2 score: 0.823508906662\n",
      "thresh: 0.2 \tF2 score: 0.824182371993\n",
      "thresh: 0.25 \tF2 score: 0.818445853154\n",
      "thresh: 0.3 \tF2 score: 0.808495691192\n",
      "thresh: 0.35 \tF2 score: 0.79794724934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_2, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "177/176 [==============================] - 35s - loss: 0.1911 - acc: 0.9214 - val_loss: 0.1978 - val_acc: 0.9196\n",
      "Epoch 2/10\n",
      "177/176 [==============================] - 31s - loss: 0.1911 - acc: 0.9220 - val_loss: 0.1960 - val_acc: 0.9198\n",
      "Epoch 3/10\n",
      "177/176 [==============================] - 31s - loss: 0.1910 - acc: 0.9219 - val_loss: 0.1979 - val_acc: 0.9187\n",
      "Epoch 4/10\n",
      "177/176 [==============================] - 31s - loss: 0.1909 - acc: 0.9212 - val_loss: 0.1967 - val_acc: 0.9197\n",
      "Epoch 5/10\n",
      "177/176 [==============================] - 31s - loss: 0.1908 - acc: 0.9219 - val_loss: 0.1965 - val_acc: 0.9209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7a78d6da0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#continue with reduced learning rate\n",
    "model1.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(lr=0.00005),\n",
    "              metrics=['accuracy']) \n",
    "model1.fit_generator(datagen.flow(x_train,y_train_2, batch_size = 128), validation_data=(x_val, y_val_2),\n",
    "                   epochs=10, steps_per_epoch=x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.790680590547\n",
      "thresh: 0.1 \tF2 score: 0.815580311007\n",
      "thresh: 0.15 \tF2 score: 0.823472020045\n",
      "thresh: 0.2 \tF2 score: 0.824594499052\n",
      "thresh: 0.25 \tF2 score: 0.819632282387\n",
      "thresh: 0.3 \tF2 score: 0.812134433882\n",
      "thresh: 0.35 \tF2 score: 0.794785413742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_2, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2180\n"
     ]
    }
   ],
   "source": [
    "num_rare = np.sum(np.sum(y_train[:,:7],axis=1)>0)\n",
    "print(num_rare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1.save(\"32_net_2\")\n",
    "model1.save_weights(\"32_net_2_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [00:52<00:00, 767.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2180, 32, 32, 3)\n",
      "(2180, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_val = []\n",
    "x_train = []\n",
    "x_train = np.zeros((num_rare,32,32,3), np.float32)\n",
    "y_train = []\n",
    "\n",
    "df_train = pd.read_csv('train_v2.csv')\n",
    "\n",
    "labels = ['blow_down',\n",
    " 'bare_ground',\n",
    " 'conventional_mine',\n",
    " 'blooming',\n",
    " 'artisinal_mine',\n",
    " 'selective_logging',         \n",
    " 'slash_burn', \n",
    " 'cultivation',\n",
    " 'habitation',\n",
    " 'road',\n",
    " 'water',\n",
    " 'haze',\n",
    " 'partly_cloudy', \n",
    " 'cloudy',\n",
    " 'agriculture',\n",
    " 'clear',\n",
    " 'primary',]\n",
    "\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}\n",
    "\n",
    "i=0\n",
    "\n",
    "for f, tags in tqdm(df_train.values[:40479], miniters=1000):    \n",
    "    img = cv2.imread('train-jpg/{}.jpg'.format(f))\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    if(np.sum(targets[:7])>0):\n",
    "        x_train[i,:,:,:] = np.array(cv2.resize(img, (32, 32)),np.float32)/255.#139 minimum size for inception\n",
    "        i+=1\n",
    "        y_train.append(targets)\n",
    "    \n",
    "y_train = np.array(y_train, np.uint8)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1962, 32, 32, 3)\n",
      "(1962, 7)\n",
      "(218, 32, 32, 3)\n",
      "(218, 7)\n"
     ]
    }
   ],
   "source": [
    "x_train -= train_mean\n",
    "x_train, x_val, y_train_3, y_val_3 = train_test_split(x_train,y_train[:,:7],test_size=0.1)\n",
    "print(x_train.shape)\n",
    "print(y_train_3.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model for the rarer classes\n",
    "from keras.models import load_model\n",
    "model2 = load_model(\"32_net_2\")\n",
    "model2.pop()\n",
    "model2.add(Dense(7, activation='sigmoid'))\n",
    "\n",
    "for layer in model2.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "model2.layers[-1].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "154/153 [==============================] - 12s - loss: 0.3063 - acc: 0.8818 - val_loss: 0.2302 - val_acc: 0.9135\n",
      "Epoch 2/10\n",
      "154/153 [==============================] - 8s - loss: 0.2429 - acc: 0.9010 - val_loss: 0.2143 - val_acc: 0.9161\n",
      "Epoch 3/10\n",
      "154/153 [==============================] - 8s - loss: 0.2356 - acc: 0.9027 - val_loss: 0.2131 - val_acc: 0.9181\n",
      "Epoch 4/10\n",
      "154/153 [==============================] - 8s - loss: 0.2319 - acc: 0.9031 - val_loss: 0.2069 - val_acc: 0.9168\n",
      "Epoch 5/10\n",
      "154/153 [==============================] - 8s - loss: 0.2263 - acc: 0.9056 - val_loss: 0.2112 - val_acc: 0.9155\n",
      "Epoch 6/10\n",
      "154/153 [==============================] - 8s - loss: 0.2263 - acc: 0.9052 - val_loss: 0.2087 - val_acc: 0.9122\n",
      "Epoch 7/10\n",
      "154/153 [==============================] - 8s - loss: 0.2242 - acc: 0.9060 - val_loss: 0.2088 - val_acc: 0.9128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7a17eaa90>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.fit_generator(datagen.flow(x_train,y_train_3, batch_size = 128), validation_data=(x_val, y_val_3),\n",
    "                  epochs=10, steps_per_epoch=10*x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )#more steps per epoch to compensate for fewer images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.723310265168\n",
      "thresh: 0.1 \tF2 score: 0.753589300608\n",
      "thresh: 0.15 \tF2 score: 0.773145114315\n",
      "thresh: 0.2 \tF2 score: 0.761868355905\n",
      "thresh: 0.25 \tF2 score: 0.751347021989\n",
      "thresh: 0.3 \tF2 score: 0.74872579001\n",
      "thresh: 0.35 \tF2 score: 0.719673802243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_3, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "154/153 [==============================] - 12s - loss: 0.2200 - acc: 0.9080 - val_loss: 0.1999 - val_acc: 0.9181\n",
      "Epoch 2/10\n",
      "154/153 [==============================] - 8s - loss: 0.2186 - acc: 0.9077 - val_loss: 0.2013 - val_acc: 0.9187\n",
      "Epoch 3/10\n",
      "154/153 [==============================] - 8s - loss: 0.2182 - acc: 0.9078 - val_loss: 0.2022 - val_acc: 0.9194\n",
      "Epoch 4/10\n",
      "154/153 [==============================] - 8s - loss: 0.2168 - acc: 0.9084 - val_loss: 0.2010 - val_acc: 0.9214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7a1629fd0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(lr=0.0005),\n",
    "              metrics=['accuracy']) \n",
    "model2.fit_generator(datagen.flow(x_train,y_train_3, batch_size = 128), validation_data=(x_val, y_val_3),\n",
    "                  epochs=10, steps_per_epoch=10*x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.735531924752\n",
      "thresh: 0.1 \tF2 score: 0.768075578855\n",
      "thresh: 0.15 \tF2 score: 0.770314547837\n",
      "thresh: 0.2 \tF2 score: 0.76878549585\n",
      "thresh: 0.25 \tF2 score: 0.763106159895\n",
      "thresh: 0.3 \tF2 score: 0.740752876074\n",
      "thresh: 0.35 \tF2 score: 0.729831076161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_3, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "154/153 [==============================] - 12s - loss: 0.2177 - acc: 0.9078 - val_loss: 0.2014 - val_acc: 0.9214\n",
      "Epoch 2/10\n",
      "154/153 [==============================] - 8s - loss: 0.2153 - acc: 0.9091 - val_loss: 0.2008 - val_acc: 0.9220\n",
      "Epoch 3/10\n",
      "154/153 [==============================] - 8s - loss: 0.2165 - acc: 0.9083 - val_loss: 0.2012 - val_acc: 0.9187\n",
      "Epoch 4/10\n",
      "154/153 [==============================] - 8s - loss: 0.2149 - acc: 0.9089 - val_loss: 0.2006 - val_acc: 0.9214\n",
      "Epoch 5/10\n",
      "154/153 [==============================] - 8s - loss: 0.2141 - acc: 0.9090 - val_loss: 0.1997 - val_acc: 0.9201\n",
      "Epoch 6/10\n",
      "154/153 [==============================] - 8s - loss: 0.2131 - acc: 0.9097 - val_loss: 0.2006 - val_acc: 0.9194\n",
      "Epoch 7/10\n",
      "154/153 [==============================] - 8s - loss: 0.2144 - acc: 0.9089 - val_loss: 0.1996 - val_acc: 0.9207\n",
      "Epoch 8/10\n",
      "154/153 [==============================] - 8s - loss: 0.2135 - acc: 0.9093 - val_loss: 0.1999 - val_acc: 0.9187\n",
      "Epoch 9/10\n",
      "154/153 [==============================] - 8s - loss: 0.2130 - acc: 0.9092 - val_loss: 0.2002 - val_acc: 0.9207\n",
      "Epoch 10/10\n",
      "154/153 [==============================] - 8s - loss: 0.2128 - acc: 0.9098 - val_loss: 0.1995 - val_acc: 0.9214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7a14797b8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(lr=0.0002),\n",
    "              metrics=['accuracy']) \n",
    "model2.fit_generator(datagen.flow(x_train,y_train_3, batch_size = 128), validation_data=(x_val, y_val_3),\n",
    "                  epochs=10, steps_per_epoch=10*x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.739354554722\n",
      "thresh: 0.1 \tF2 score: 0.75962276765\n",
      "thresh: 0.15 \tF2 score: 0.777752128096\n",
      "thresh: 0.2 \tF2 score: 0.778360273773\n",
      "thresh: 0.25 \tF2 score: 0.769659239843\n",
      "thresh: 0.3 \tF2 score: 0.758082131935\n",
      "thresh: 0.35 \tF2 score: 0.737257900102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_3, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "154/153 [==============================] - 12s - loss: 0.2134 - acc: 0.9090 - val_loss: 0.1986 - val_acc: 0.9214\n",
      "Epoch 2/10\n",
      "154/153 [==============================] - 8s - loss: 0.2105 - acc: 0.9110 - val_loss: 0.1998 - val_acc: 0.9207\n",
      "Epoch 3/10\n",
      "154/153 [==============================] - 8s - loss: 0.2129 - acc: 0.9098 - val_loss: 0.1990 - val_acc: 0.9207\n",
      "Epoch 4/10\n",
      "154/153 [==============================] - 8s - loss: 0.2112 - acc: 0.9100 - val_loss: 0.1987 - val_acc: 0.9207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7a12bbdd8>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(lr=0.0001),\n",
    "              metrics=['accuracy']) \n",
    "model2.fit_generator(datagen.flow(x_train,y_train_3, batch_size = 128), validation_data=(x_val, y_val_3),\n",
    "                  epochs=10, steps_per_epoch=10*x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.738817566226\n",
      "thresh: 0.1 \tF2 score: 0.763055687941\n",
      "thresh: 0.15 \tF2 score: 0.778933668269\n",
      "thresh: 0.2 \tF2 score: 0.770715013834\n",
      "thresh: 0.25 \tF2 score: 0.77126110383\n",
      "thresh: 0.3 \tF2 score: 0.757317605941\n",
      "thresh: 0.35 \tF2 score: 0.734199796126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict(x_val,batch_size=128)\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",fbeta_score(y_val_3, np.array(y_pred)>thresh, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "154/153 [==============================] - 12s - loss: 0.2124 - acc: 0.9103 - val_loss: 0.1995 - val_acc: 0.9201\n",
      "Epoch 2/10\n",
      "154/153 [==============================] - 8s - loss: 0.2133 - acc: 0.9096 - val_loss: 0.1986 - val_acc: 0.9207\n",
      "Epoch 3/10\n",
      "154/153 [==============================] - 8s - loss: 0.2117 - acc: 0.9107 - val_loss: 0.1987 - val_acc: 0.9214\n",
      "Epoch 4/10\n",
      "154/153 [==============================] - 8s - loss: 0.2130 - acc: 0.9086 - val_loss: 0.1991 - val_acc: 0.9194\n",
      "Epoch 5/10\n",
      "154/153 [==============================] - 8s - loss: 0.2128 - acc: 0.9095 - val_loss: 0.1991 - val_acc: 0.9220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7a108c438>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(lr=0.00005),\n",
    "              metrics=['accuracy']) \n",
    "model2.fit_generator(datagen.flow(x_train,y_train_3, batch_size = 128), validation_data=(x_val, y_val_3),\n",
    "                  epochs=10, steps_per_epoch=10*x_train.shape[0]/ 128, callbacks=callbacks,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh: 0.05 \tF2 score: 0.740028065716\n",
      "thresh: 0.1 \tF2 score: 0.763820213935\n",
      "thresh: 0.15 \tF2 score: 0.777404616281\n",
      "thresh: 0.2 \tF2 score: 0.774537643804\n",
      "thresh: 0.25 \tF2 score: 0.765618173875\n",
      "thresh: 0.3 \tF2 score: 0.753494975972\n",
      "thresh: 0.35 \tF2 score: 0.738022426096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict(x_val,batch_size=128)\n",
    "bestthresh = 0\n",
    "bestF2score = 0\n",
    "for thresh in [0.05,0.1,0.15,0.2,0.25,0.3,0.35]:\n",
    "    F2score = fbeta_score(y_val_3, np.array(y_pred)>thresh, beta=2, average='samples')\n",
    "    print(\"thresh:\",thresh,\"\\tF2 score:\",F2score)\n",
    "    if F2score > bestF2score:\n",
    "        bestthresh = thresh\n",
    "        bestF2score = F2score    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>TP</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blow_down</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>198</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bare_ground</th>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conventional_mine</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>201</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blooming</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>155</td>\n",
       "      <td>42</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artisinal_mine</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>166</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selective_logging</th>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>149</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slash_burn</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>172</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   FN  FP   TN  TP  Total\n",
       "blow_down           4  11  198   5      9\n",
       "bare_ground         4  71   65  78     82\n",
       "conventional_mine   2  12  201   3      5\n",
       "blooming            5  16  155  42     47\n",
       "artisinal_mine      1  23  166  28     29\n",
       "selective_logging   7  40  149  22     29\n",
       "slash_burn          3  23  172  20     23"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total,tp,tn,fp,fn = multilabelmetrics(y_val_3,np.array(y_pred)>bestthresh)\n",
    "d = {'Total':total,'TP':tp,'TN':tn,'FP':fp,'FN':fn}\n",
    "pd.DataFrame(d, index=labels[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2.save(\"32_net_3\")\n",
    "model2.save_weights(\"32_net_3_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40479 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1000/40479 [00:01<00:52, 745.81it/s]\u001b[A\n",
      "  5%|▍         | 2000/40479 [00:02<00:52, 739.01it/s]\u001b[A\n",
      "  7%|▋         | 3000/40479 [00:04<00:51, 733.43it/s]\u001b[A\n",
      "100%|██████████| 40479/40479 [00:54<00:00, 744.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 32, 32, 3)\n",
      "(40479, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#F2 score on training set\n",
    "x_val = []\n",
    "x_train = []\n",
    "x_train = np.zeros((40479,32,32,3), np.float32)\n",
    "y_train = []\n",
    "\n",
    "df_train = pd.read_csv('train_v2.csv')\n",
    "\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}\n",
    "\n",
    "i=0\n",
    "\n",
    "for f, tags in tqdm(df_train.values[:40479], miniters=1000):    \n",
    "    img = cv2.imread('train-jpg/{}.jpg'.format(f))\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    x_train[i,:,:,:] = np.array(cv2.resize(img, (32, 32)),np.float32)/255.#139 minimum size for inception\n",
    "    i+=1\n",
    "    y_train.append(targets)\n",
    "\n",
    "y_train = np.array(y_train, np.uint8)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train -= train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = model.predict(x_train,batch_size=128)\n",
    "y1 = model1.predict(x_train,batch_size=128)\n",
    "y2 = model2.predict(x_train,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 4)\n",
      "(40479, 8)\n",
      "(40479, 7)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(y1.shape)\n",
    "print(y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combine_predictions_2(y,y1,y2,thresh):\n",
    "    y_pred = np.zeros((y.shape[0],17),np.uint8)\n",
    "    y_bool = np.array((y[:,1:] > thresh[0:3]),np.uint8)\n",
    "    y1_bool = np.array((y1[:,1:] > thresh[3:10])*np.tile(y[:,0]>thresh[17],(7,1)).T,np.uint8)\n",
    "    y2_bool = np.array((y2 > thresh[10:17])*np.tile(y1[:,0]>thresh[18],(7,1)).T,np.uint8)\n",
    "    y_pred[:,:7] = y2_bool\n",
    "    y_pred[:,7:14] = y1_bool\n",
    "    y_pred[:,14:17] = y_bool\n",
    "    y_pred[((np.nonzero(y1[:,-1]>thresh[19]))[0]),:] = 0\n",
    "    y_pred[((np.nonzero(y1[:,-1]>thresh[19]))[0]),13] = 1\n",
    "    return y_pred\n",
    "\n",
    "def optimise_f2_thresholds(x_init,y, y1,y2, ytrue, num_thresh=20, verbose=True, resolution=100):\n",
    "  def mf(x):\n",
    "    p2 = combine_predictions_2(y, y1,y2,x)\n",
    "    score = fbeta_score(ytrue, p2, beta=2, average='samples')\n",
    "    return score\n",
    "\n",
    "  x = list(x_init)\n",
    "  for i in range(num_thresh):\n",
    "    best_i2 = 0\n",
    "    best_score = 0\n",
    "    for i2 in range(resolution):\n",
    "      i2 /= resolution\n",
    "      x[i] = i2\n",
    "      score = mf(x)\n",
    "      if score > best_score:\n",
    "        best_i2 = i2\n",
    "        best_score = score\n",
    "    x[i] = best_i2\n",
    "    if verbose:\n",
    "      print(i, best_i2, best_score)\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.22 0.896853143732\n",
      "1 0.17 0.896898377013\n",
      "2 0.26 0.896918140142\n",
      "3 0.23 0.896974259947\n",
      "4 0.23 0.897018173566\n",
      "5 0.25 0.89715743809\n",
      "6 0.32 0.897456768996\n",
      "7 0.21 0.89747181798\n",
      "8 0.26 0.897521828877\n",
      "9 0.09 0.897772112092\n",
      "10 0.58 0.89838891842\n",
      "11 0.55 0.898678831248\n",
      "12 0.33 0.89871037124\n",
      "13 0.98 0.911761929332\n",
      "14 0.34 0.911815461304\n",
      "15 0.55 0.913958463848\n",
      "16 0.64 0.914217217736\n",
      "17 0.3 0.914336717765\n",
      "18 0.26 0.914467271068\n",
      "19 0.79 0.923470509553\n"
     ]
    }
   ],
   "source": [
    "thresh = optimise_f2_thresholds([0.2]*20,y,y1,y2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.22 0.923470509553\n",
      "1 0.17 0.923470509553\n",
      "2 0.21 0.923500804629\n",
      "3 0.23 0.923500804629\n",
      "4 0.23 0.923500804629\n",
      "5 0.25 0.923500804629\n",
      "6 0.26 0.923579304446\n",
      "7 0.19 0.923602453014\n",
      "8 0.26 0.923602453014\n",
      "9 0.09 0.923602453014\n",
      "10 0.52 0.923604603154\n",
      "11 0.32 0.923621863812\n",
      "12 0.28 0.92362471222\n",
      "13 0.98 0.92362471222\n",
      "14 0.34 0.92362471222\n",
      "15 0.55 0.92362471222\n",
      "16 0.5 0.923624933508\n",
      "17 0.3 0.923624933508\n",
      "18 0.27 0.923633580271\n",
      "19 0.79 0.923633580271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "thresh = optimise_f2_thresholds(thresh,y,y1,y2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>TP</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blow_down</th>\n",
       "      <td>90</td>\n",
       "      <td>16</td>\n",
       "      <td>40365</td>\n",
       "      <td>8</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bare_ground</th>\n",
       "      <td>437</td>\n",
       "      <td>876</td>\n",
       "      <td>38741</td>\n",
       "      <td>425</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conventional_mine</th>\n",
       "      <td>58</td>\n",
       "      <td>45</td>\n",
       "      <td>40334</td>\n",
       "      <td>42</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blooming</th>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>40147</td>\n",
       "      <td>0</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artisinal_mine</th>\n",
       "      <td>72</td>\n",
       "      <td>190</td>\n",
       "      <td>39950</td>\n",
       "      <td>267</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selective_logging</th>\n",
       "      <td>236</td>\n",
       "      <td>193</td>\n",
       "      <td>39946</td>\n",
       "      <td>104</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slash_burn</th>\n",
       "      <td>198</td>\n",
       "      <td>21</td>\n",
       "      <td>40249</td>\n",
       "      <td>11</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cultivation</th>\n",
       "      <td>1087</td>\n",
       "      <td>3821</td>\n",
       "      <td>32181</td>\n",
       "      <td>3390</td>\n",
       "      <td>4477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>habitation</th>\n",
       "      <td>874</td>\n",
       "      <td>2390</td>\n",
       "      <td>34429</td>\n",
       "      <td>2786</td>\n",
       "      <td>3660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>road</th>\n",
       "      <td>851</td>\n",
       "      <td>3894</td>\n",
       "      <td>28514</td>\n",
       "      <td>7220</td>\n",
       "      <td>8071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>1266</td>\n",
       "      <td>3008</td>\n",
       "      <td>30060</td>\n",
       "      <td>6145</td>\n",
       "      <td>7411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haze</th>\n",
       "      <td>391</td>\n",
       "      <td>1523</td>\n",
       "      <td>36259</td>\n",
       "      <td>2306</td>\n",
       "      <td>2697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partly_cloudy</th>\n",
       "      <td>174</td>\n",
       "      <td>1177</td>\n",
       "      <td>32041</td>\n",
       "      <td>7087</td>\n",
       "      <td>7261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloudy</th>\n",
       "      <td>31</td>\n",
       "      <td>1137</td>\n",
       "      <td>37253</td>\n",
       "      <td>2058</td>\n",
       "      <td>2089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agriculture</th>\n",
       "      <td>714</td>\n",
       "      <td>3983</td>\n",
       "      <td>24181</td>\n",
       "      <td>11601</td>\n",
       "      <td>12315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clear</th>\n",
       "      <td>211</td>\n",
       "      <td>2175</td>\n",
       "      <td>9873</td>\n",
       "      <td>28220</td>\n",
       "      <td>28431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>primary</th>\n",
       "      <td>115</td>\n",
       "      <td>1225</td>\n",
       "      <td>1741</td>\n",
       "      <td>37398</td>\n",
       "      <td>37513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     FN    FP     TN     TP  Total\n",
       "blow_down            90    16  40365      8     98\n",
       "bare_ground         437   876  38741    425    862\n",
       "conventional_mine    58    45  40334     42    100\n",
       "blooming            332     0  40147      0    332\n",
       "artisinal_mine       72   190  39950    267    339\n",
       "selective_logging   236   193  39946    104    340\n",
       "slash_burn          198    21  40249     11    209\n",
       "cultivation        1087  3821  32181   3390   4477\n",
       "habitation          874  2390  34429   2786   3660\n",
       "road                851  3894  28514   7220   8071\n",
       "water              1266  3008  30060   6145   7411\n",
       "haze                391  1523  36259   2306   2697\n",
       "partly_cloudy       174  1177  32041   7087   7261\n",
       "cloudy               31  1137  37253   2058   2089\n",
       "agriculture         714  3983  24181  11601  12315\n",
       "clear               211  2175   9873  28220  28431\n",
       "primary             115  1225   1741  37398  37513"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = combine_predictions_2(y,y1,y2,thresh)\n",
    "total,tp,tn,fp,fn = multilabelmetrics(y_train,y_pred)\n",
    "d = {'Total':total,'TP':tp,'TN':tn,'FP':fp,'FN':fn}\n",
    "pd.DataFrame(d, index=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61191/61191 [02:03<00:00, 494.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61191, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Test set\n",
    "x_train = []\n",
    "x_val = []\n",
    "x_test = np.zeros((61191,32,32,3), np.float32)\n",
    "y_train = []\n",
    "\n",
    "df_test = pd.read_csv('sample_submission_v2.csv')\n",
    "\n",
    "i = 0 \n",
    "for f, tags in tqdm(df_test.values, miniters=1000):\n",
    "    img = cv2.imread('test-jpg/{}.jpg'.format(f))\n",
    "    x_test[i,:,:,:] = np.array(cv2.resize(img, (32, 32)),np.float32)/255.#139 minimum size for inception\n",
    "    i+=1\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test -= train_mean\n",
    "\n",
    "y = model.predict(x_test,batch_size=128)\n",
    "y1 = model1.predict(x_test,batch_size=128)\n",
    "y2 = model2.predict(x_test,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = combine_predictions_2(y,y1,y2,thresh)\n",
    "labels_np = np.array(labels)\n",
    "preds = [' '.join(labels_np[np.array(y_pred[i,:],bool)]) for i in range(y_pred.shape[0])]\n",
    "subm = pd.DataFrame()\n",
    "subm['image_name'] = df_test.values[:,0]\n",
    "subm['tags'] = preds\n",
    "subm.to_csv('submission_32_net_1.csv', index=False)\n",
    "#test set score:0.91567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
