{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch import np # Torch wrapper for Numpy\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import Sampler, SequentialSampler, SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_PATH = 'train-jpg/'\n",
    "IMG_EXT = '.jpg'\n",
    "TRAIN_DATA = 'train_label.csv'\n",
    "\n",
    "TEST_PATH = 'test-jpg/'\n",
    "TEST_DATA = 'sample_submission_v2.csv'\n",
    "\n",
    "NUM_CLASSES = 17\n",
    "NUM_TRAIN = 37479\n",
    "NUM_VAL = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class KaggleAmazonDataset(Dataset):\n",
    "    \"\"\"Dataset wrapping images and target labels for Kaggle - Planet Amazon from Space competition.\n",
    "\n",
    "    Arguments:\n",
    "        A CSV file path\n",
    "        Path to image folder\n",
    "        Extension of images\n",
    "        PIL transforms\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_path, img_path, img_ext, transform=None, split = 'train'):\n",
    "    \n",
    "        tmp_df = pd.read_csv(csv_path)\n",
    "        assert tmp_df['image_name'].apply(lambda x: os.path.isfile(img_path + x + img_ext)).all(), \\\n",
    "\"Some images referenced in the CSV file were not found\"\n",
    "        \n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        self.img_path = img_path\n",
    "        self.img_ext = img_ext\n",
    "        self.transform = transform\n",
    "\n",
    "        self.X_train = tmp_df['image_name']\n",
    "        self.y_train = None\n",
    "        if split == 'train':\n",
    "            self.y_train = self.mlb.fit_transform(tmp_df['tags'].str.split()).astype(np.float32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path + self.X_train[index] + self.img_ext)\n",
    "        img = img.convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        if self.y_train is not None:\n",
    "            label = torch.from_numpy(self.y_train[index])\n",
    "            return img, label\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def randomTranspose(x):\n",
    "    if random.random() < 0.5:\n",
    "        x = x.transpose(1,2)\n",
    "    return x\n",
    "\n",
    "transformations = transforms.Compose([transforms.Scale(256),transforms.RandomHorizontalFlip(), \\\n",
    "                                      transforms.ToTensor(), transforms.Lambda(lambda x: randomTranspose(x)) ])\n",
    "#, transforms.Lambda(lambda x: randomTranspose(x.numpy()))\n",
    "dset_train = KaggleAmazonDataset(TRAIN_DATA,IMG_PATH,IMG_EXT,transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# class ChunkSampler(Sampler):\n",
    "#     \"\"\"Samples elements sequentially from some offset. \n",
    "#     Arguments:\n",
    "#         num_samples: # of desired datapoints\n",
    "#         start: offset where we should start selecting from\n",
    "#     \"\"\"\n",
    "#     def __init__(self, num_samples, start = 0):\n",
    "#         self.num_samples = num_samples\n",
    "#         self.start = start\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.num_samples\n",
    "    \n",
    "\n",
    "# loader_train = DataLoader(dset_train, batch_size=64, sampler=ChunkSampler(NUM_TRAIN, 0))\n",
    "\n",
    "# loader_val = DataLoader(dset_train, batch_size=64, sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dtype = torch.FloatTensor\n",
    "dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "#         self.conv2_drop = nn.Dropout2d()\n",
    "#         self.fc1 = nn.Linear(2304, 256)\n",
    "#         self.fc2 = nn.Linear(256, 17)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "#         x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "#         x = x.view(x.size(0), -1) # Flatten layer\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "#         x = self.fc2(x)\n",
    "#         return F.sigmoid(x)\n",
    "\n",
    "# # model = Net() # On CPU\n",
    "# model = Net().cuda() # On GPU\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.pretrained_model = pretrained_model\n",
    "        self.last_layer = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.last_layer(self.pretrained_model(x))\n",
    "\n",
    "pretrained_model = torchvision.models.resnet18(pretrained=True)\n",
    "pretrained_model.fc = nn.Linear(pretrained_model.fc.in_features, NUM_CLASSES)\n",
    "# print(pretrained_model)\n",
    "model = MyModel(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.type(dtype)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.pretrained_model.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.pretrained_model.fc.parameters(), lr=1e-3)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dset_train,\n",
    "                          batch_size=32,\n",
    "                          shuffle = True,\n",
    "                          drop_last = True,\n",
    "                          num_workers=1, # 1 for CUDA\n",
    "#                           sampler = ChunkSampler(NUM_TRAIN, 0),\n",
    "#                           sampler = SubsetRandomSampler(range(NUM_TRAIN)),\n",
    "                          pin_memory=True # CUDA only\n",
    "                         )\n",
    "\n",
    "# val_loader = DataLoader(dset_train,\n",
    "#                           batch_size=32,\n",
    "#                           drop_last = True,\n",
    "#                           num_workers=1, # 1 for CUDA\n",
    "# #                           sampler = ChunkSampler(NUM_VAL, NUM_TRAIN),\n",
    "#                           sampler = SubsetRandomSampler(range(NUM_TRAIN, NUM_TRAIN + NUM_VAL)),\n",
    "#                           pin_memory=True # CUDA only\n",
    "#                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.cuda(async=True), target.cuda(async=True) # On GPU\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.binary_cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "        \n",
    "#     model.eval()\n",
    "#     val_num = 0\n",
    "#     val_score = 0\n",
    "#     val_loss = 0\n",
    "    \n",
    "#     for batch_idx, (data, target) in enumerate(val_loader):\n",
    "#         data, target = data.cuda(async=True), target.cuda(async=True) # On GPU\n",
    "#         data, target = Variable(data), Variable(target)\n",
    "#         output = model(data)\n",
    "#         loss = F.binary_cross_entropy(output, target)\n",
    "        \n",
    "#         val_num += len(data)\n",
    "#         val_loss += loss\n",
    "        \n",
    "#     val_loss /= val_num\n",
    "#     print(\"Val loss: {:.6f}\".format(val_loss))\n",
    "\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/40479 (0%)]\tLoss: 0.828939\n",
      "Train Epoch: 1 [3200/40479 (8%)]\tLoss: 0.207056\n",
      "Train Epoch: 1 [6400/40479 (16%)]\tLoss: 0.152558\n",
      "Train Epoch: 1 [9600/40479 (24%)]\tLoss: 0.202723\n",
      "Train Epoch: 1 [12800/40479 (32%)]\tLoss: 0.161529\n",
      "Train Epoch: 1 [16000/40479 (40%)]\tLoss: 0.123555\n",
      "Train Epoch: 1 [19200/40479 (47%)]\tLoss: 0.158530\n",
      "Train Epoch: 1 [22400/40479 (55%)]\tLoss: 0.114603\n",
      "Train Epoch: 1 [25600/40479 (63%)]\tLoss: 0.145887\n",
      "Train Epoch: 1 [28800/40479 (71%)]\tLoss: 0.131140\n",
      "Train Epoch: 1 [32000/40479 (79%)]\tLoss: 0.146387\n",
      "Train Epoch: 1 [35200/40479 (87%)]\tLoss: 0.129689\n",
      "Train Epoch: 1 [38400/40479 (95%)]\tLoss: 0.115407\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 2):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/40479 (0%)]\tLoss: 0.123179\n",
      "Train Epoch: 1 [3200/40479 (8%)]\tLoss: 0.086397\n",
      "Train Epoch: 1 [6400/40479 (16%)]\tLoss: 0.141070\n",
      "Train Epoch: 1 [9600/40479 (24%)]\tLoss: 0.140612\n",
      "Train Epoch: 1 [12800/40479 (32%)]\tLoss: 0.209979\n",
      "Train Epoch: 1 [16000/40479 (40%)]\tLoss: 0.148314\n",
      "Train Epoch: 1 [19200/40479 (47%)]\tLoss: 0.156550\n",
      "Train Epoch: 1 [22400/40479 (55%)]\tLoss: 0.154521\n",
      "Train Epoch: 1 [25600/40479 (63%)]\tLoss: 0.111946\n",
      "Train Epoch: 1 [28800/40479 (71%)]\tLoss: 0.103581\n",
      "Train Epoch: 1 [32000/40479 (79%)]\tLoss: 0.154220\n",
      "Train Epoch: 1 [35200/40479 (87%)]\tLoss: 0.112811\n",
      "Train Epoch: 1 [38400/40479 (95%)]\tLoss: 0.109570\n",
      "Train Epoch: 2 [0/40479 (0%)]\tLoss: 0.107110\n",
      "Train Epoch: 2 [3200/40479 (8%)]\tLoss: 0.147493\n",
      "Train Epoch: 2 [6400/40479 (16%)]\tLoss: 0.153570\n",
      "Train Epoch: 2 [9600/40479 (24%)]\tLoss: 0.156646\n",
      "Train Epoch: 2 [12800/40479 (32%)]\tLoss: 0.141089\n",
      "Train Epoch: 2 [16000/40479 (40%)]\tLoss: 0.143304\n",
      "Train Epoch: 2 [19200/40479 (47%)]\tLoss: 0.186163\n",
      "Train Epoch: 2 [22400/40479 (55%)]\tLoss: 0.123262\n",
      "Train Epoch: 2 [25600/40479 (63%)]\tLoss: 0.146401\n",
      "Train Epoch: 2 [28800/40479 (71%)]\tLoss: 0.130299\n",
      "Train Epoch: 2 [32000/40479 (79%)]\tLoss: 0.144750\n",
      "Train Epoch: 2 [35200/40479 (87%)]\tLoss: 0.125175\n",
      "Train Epoch: 2 [38400/40479 (95%)]\tLoss: 0.119777\n",
      "Train Epoch: 3 [0/40479 (0%)]\tLoss: 0.101201\n",
      "Train Epoch: 3 [3200/40479 (8%)]\tLoss: 0.129421\n",
      "Train Epoch: 3 [6400/40479 (16%)]\tLoss: 0.145039\n",
      "Train Epoch: 3 [9600/40479 (24%)]\tLoss: 0.140369\n",
      "Train Epoch: 3 [12800/40479 (32%)]\tLoss: 0.148761\n",
      "Train Epoch: 3 [16000/40479 (40%)]\tLoss: 0.151408\n",
      "Train Epoch: 3 [19200/40479 (47%)]\tLoss: 0.123051\n",
      "Train Epoch: 3 [22400/40479 (55%)]\tLoss: 0.130922\n",
      "Train Epoch: 3 [25600/40479 (63%)]\tLoss: 0.098197\n",
      "Train Epoch: 3 [28800/40479 (71%)]\tLoss: 0.116203\n",
      "Train Epoch: 3 [32000/40479 (79%)]\tLoss: 0.158400\n",
      "Train Epoch: 3 [35200/40479 (87%)]\tLoss: 0.106899\n",
      "Train Epoch: 3 [38400/40479 (95%)]\tLoss: 0.143795\n",
      "Train Epoch: 4 [0/40479 (0%)]\tLoss: 0.181628\n",
      "Train Epoch: 4 [3200/40479 (8%)]\tLoss: 0.130232\n",
      "Train Epoch: 4 [6400/40479 (16%)]\tLoss: 0.107853\n",
      "Train Epoch: 4 [9600/40479 (24%)]\tLoss: 0.112206\n",
      "Train Epoch: 4 [12800/40479 (32%)]\tLoss: 0.108888\n",
      "Train Epoch: 4 [16000/40479 (40%)]\tLoss: 0.128628\n",
      "Train Epoch: 4 [19200/40479 (47%)]\tLoss: 0.135735\n",
      "Train Epoch: 4 [22400/40479 (55%)]\tLoss: 0.121037\n",
      "Train Epoch: 4 [25600/40479 (63%)]\tLoss: 0.155480\n",
      "Train Epoch: 4 [28800/40479 (71%)]\tLoss: 0.152094\n",
      "Train Epoch: 4 [32000/40479 (79%)]\tLoss: 0.182639\n",
      "Train Epoch: 4 [35200/40479 (87%)]\tLoss: 0.107231\n",
      "Train Epoch: 4 [38400/40479 (95%)]\tLoss: 0.131360\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 5):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/40479 (0%)]\tLoss: 0.171668\n",
      "Train Epoch: 1 [3200/40479 (8%)]\tLoss: 0.149592\n",
      "Train Epoch: 1 [6400/40479 (16%)]\tLoss: 0.120410\n",
      "Train Epoch: 1 [9600/40479 (24%)]\tLoss: 0.175223\n",
      "Train Epoch: 1 [12800/40479 (32%)]\tLoss: 0.097989\n",
      "Train Epoch: 1 [16000/40479 (40%)]\tLoss: 0.155856\n",
      "Train Epoch: 1 [19200/40479 (47%)]\tLoss: 0.135132\n",
      "Train Epoch: 1 [22400/40479 (55%)]\tLoss: 0.192863\n",
      "Train Epoch: 1 [25600/40479 (63%)]\tLoss: 0.129870\n",
      "Train Epoch: 1 [28800/40479 (71%)]\tLoss: 0.115218\n",
      "Train Epoch: 1 [32000/40479 (79%)]\tLoss: 0.135781\n",
      "Train Epoch: 1 [35200/40479 (87%)]\tLoss: 0.147131\n",
      "Train Epoch: 1 [38400/40479 (95%)]\tLoss: 0.184221\n",
      "Train Epoch: 2 [0/40479 (0%)]\tLoss: 0.136432\n",
      "Train Epoch: 2 [3200/40479 (8%)]\tLoss: 0.138501\n",
      "Train Epoch: 2 [6400/40479 (16%)]\tLoss: 0.146924\n",
      "Train Epoch: 2 [9600/40479 (24%)]\tLoss: 0.133526\n",
      "Train Epoch: 2 [12800/40479 (32%)]\tLoss: 0.159796\n",
      "Train Epoch: 2 [16000/40479 (40%)]\tLoss: 0.182151\n",
      "Train Epoch: 2 [19200/40479 (47%)]\tLoss: 0.149135\n",
      "Train Epoch: 2 [22400/40479 (55%)]\tLoss: 0.158292\n",
      "Train Epoch: 2 [25600/40479 (63%)]\tLoss: 0.147335\n",
      "Train Epoch: 2 [28800/40479 (71%)]\tLoss: 0.118886\n",
      "Train Epoch: 2 [32000/40479 (79%)]\tLoss: 0.143254\n",
      "Train Epoch: 2 [35200/40479 (87%)]\tLoss: 0.148531\n",
      "Train Epoch: 2 [38400/40479 (95%)]\tLoss: 0.103778\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 3):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/40479 (0%)]\tLoss: 0.120348\n",
      "Train Epoch: 1 [3200/40479 (8%)]\tLoss: 0.131251\n",
      "Train Epoch: 1 [6400/40479 (16%)]\tLoss: 0.117261\n",
      "Train Epoch: 1 [9600/40479 (24%)]\tLoss: 0.140783\n",
      "Train Epoch: 1 [12800/40479 (32%)]\tLoss: 0.105033\n",
      "Train Epoch: 1 [16000/40479 (40%)]\tLoss: 0.119596\n",
      "Train Epoch: 1 [19200/40479 (47%)]\tLoss: 0.136888\n",
      "Train Epoch: 1 [22400/40479 (55%)]\tLoss: 0.145551\n",
      "Train Epoch: 1 [25600/40479 (63%)]\tLoss: 0.130579\n",
      "Train Epoch: 1 [28800/40479 (71%)]\tLoss: 0.156442\n",
      "Train Epoch: 1 [32000/40479 (79%)]\tLoss: 0.149531\n",
      "Train Epoch: 1 [35200/40479 (87%)]\tLoss: 0.143198\n",
      "Train Epoch: 1 [38400/40479 (95%)]\tLoss: 0.163327\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.pretrained_model.fc.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(1, 2):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/40479 (0%)]\tLoss: 0.151192\n",
      "Train Epoch: 1 [3200/40479 (8%)]\tLoss: 0.138406\n",
      "Train Epoch: 1 [6400/40479 (16%)]\tLoss: 0.137685\n",
      "Train Epoch: 1 [9600/40479 (24%)]\tLoss: 0.116214\n",
      "Train Epoch: 1 [12800/40479 (32%)]\tLoss: 0.137760\n",
      "Train Epoch: 1 [16000/40479 (40%)]\tLoss: 0.102601\n",
      "Train Epoch: 1 [19200/40479 (47%)]\tLoss: 0.151126\n",
      "Train Epoch: 1 [22400/40479 (55%)]\tLoss: 0.110171\n",
      "Train Epoch: 1 [25600/40479 (63%)]\tLoss: 0.100256\n",
      "Train Epoch: 1 [28800/40479 (71%)]\tLoss: 0.107878\n",
      "Train Epoch: 1 [32000/40479 (79%)]\tLoss: 0.162737\n",
      "Train Epoch: 1 [35200/40479 (87%)]\tLoss: 0.113197\n",
      "Train Epoch: 1 [38400/40479 (95%)]\tLoss: 0.115904\n",
      "Train Epoch: 2 [0/40479 (0%)]\tLoss: 0.093670\n",
      "Train Epoch: 2 [3200/40479 (8%)]\tLoss: 0.123251\n",
      "Train Epoch: 2 [6400/40479 (16%)]\tLoss: 0.126515\n",
      "Train Epoch: 2 [9600/40479 (24%)]\tLoss: 0.150035\n",
      "Train Epoch: 2 [12800/40479 (32%)]\tLoss: 0.125778\n",
      "Train Epoch: 2 [16000/40479 (40%)]\tLoss: 0.158569\n",
      "Train Epoch: 2 [19200/40479 (47%)]\tLoss: 0.145509\n",
      "Train Epoch: 2 [22400/40479 (55%)]\tLoss: 0.134453\n",
      "Train Epoch: 2 [25600/40479 (63%)]\tLoss: 0.130674\n",
      "Train Epoch: 2 [28800/40479 (71%)]\tLoss: 0.136006\n",
      "Train Epoch: 2 [32000/40479 (79%)]\tLoss: 0.102791\n",
      "Train Epoch: 2 [35200/40479 (87%)]\tLoss: 0.095224\n",
      "Train Epoch: 2 [38400/40479 (95%)]\tLoss: 0.144412\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 3):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Construct a new Optimizer that will update all model parameters. Note the\n",
    "# small learning rate.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/40479 (0%)]\tLoss: 0.127204\n",
      "Train Epoch: 1 [3200/40479 (8%)]\tLoss: 0.136197\n",
      "Train Epoch: 1 [6400/40479 (16%)]\tLoss: 0.082399\n",
      "Train Epoch: 1 [9600/40479 (24%)]\tLoss: 0.110119\n",
      "Train Epoch: 1 [12800/40479 (32%)]\tLoss: 0.148342\n",
      "Train Epoch: 1 [16000/40479 (40%)]\tLoss: 0.115964\n",
      "Train Epoch: 1 [19200/40479 (47%)]\tLoss: 0.132456\n",
      "Train Epoch: 1 [22400/40479 (55%)]\tLoss: 0.170865\n",
      "Train Epoch: 1 [25600/40479 (63%)]\tLoss: 0.095612\n",
      "Train Epoch: 1 [28800/40479 (71%)]\tLoss: 0.107046\n",
      "Train Epoch: 1 [32000/40479 (79%)]\tLoss: 0.085151\n",
      "Train Epoch: 1 [35200/40479 (87%)]\tLoss: 0.077145\n",
      "Train Epoch: 1 [38400/40479 (95%)]\tLoss: 0.115007\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 2):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/40479 (0%)]\tLoss: 0.098843\n",
      "Train Epoch: 1 [3200/40479 (8%)]\tLoss: 0.063813\n",
      "Train Epoch: 1 [6400/40479 (16%)]\tLoss: 0.073177"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 5):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, 4):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import optimise_f2_thresholds\n",
    "def find_best_thresholds():\n",
    "    train_loader = DataLoader(dset_train,\n",
    "                          batch_size=32,\n",
    "                          drop_last = True,\n",
    "                          num_workers=1, # 1 for CUDA\n",
    "                         # pin_memory=True # CUDA only\n",
    "                         )\n",
    "    \n",
    "    model.eval()\n",
    "    train_num = 0\n",
    "    predictions = np.zeros((dset_train.__len__(), NUM_CLASSES ))\n",
    "    true_labels = np.zeros((dset_train.__len__(), NUM_CLASSES ))\n",
    "    for batch_idx, (data, target) in enumerate(train_loader, 0):\n",
    "        data = data.cuda(async=True) # On GPU\n",
    "        data = Variable(data)\n",
    "        output = model(data)\n",
    "        \n",
    "        batch_size = len(data)\n",
    "        train_num += batch_size\n",
    "        \n",
    "        start = train_num - batch_size\n",
    "        end = train_num\n",
    "        predictions[start:end] = output.data.cpu().numpy().reshape(-1,NUM_CLASSES)\n",
    "        true_labels[start:end] = target.cpu().numpy().reshape(-1, NUM_CLASSES)\n",
    "        \n",
    "    thresh = optimise_f2_thresholds(true_labels, predictions)\n",
    "    \n",
    "    return thresh\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.19 0.935949303651\n",
      "1 0.24 0.93596613717\n",
      "2 0.13 0.93605152513\n",
      "3 0.34 0.936141211012\n",
      "4 0.13 0.936164196754\n",
      "5 0.18 0.936219753937\n",
      "6 0.06 0.936920077516\n",
      "7 0.18 0.936925966846\n",
      "8 0.18 0.937084065383\n",
      "9 0.14 0.937139906395\n",
      "10 0.25 0.937310623385\n",
      "11 0.17 0.937341140884\n",
      "12 0.29 0.937517349047\n",
      "13 0.18 0.937567371028\n",
      "14 0.2 0.937567371028\n",
      "15 0.11 0.937640218572\n",
      "16 0.16 0.937712715456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cs231n/myVE35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "thresh = find_best_thresholds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dset_test = KaggleAmazonDataset(TEST_DATA,TEST_PATH,IMG_EXT, transformations, split = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dset_test,\n",
    "                          batch_size = 128,\n",
    "                          drop_last = False,\n",
    "                          sampler = SequentialSampler(dset_test),\n",
    "                          num_workers=4 # 1 for CUDA\n",
    "                         # pin_memory=True # CUDA only\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61191"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(test_loader):\n",
    "    model.eval()\n",
    "    test_num = 0\n",
    "    predictions = np.zeros((dset_test.__len__(), NUM_CLASSES ))\n",
    "    for batch_idx, data in enumerate(test_loader, 0):\n",
    "        data = data.cuda(async=True) # On GPU\n",
    "        data = Variable(data)\n",
    "        output = model(data)\n",
    "        \n",
    "        batch_size = len(data)\n",
    "        test_num += batch_size\n",
    "        \n",
    "        start = test_num - batch_size\n",
    "        end = test_num\n",
    "        predictions[start:end] = output.data.cpu().numpy().reshape(-1,NUM_CLASSES)\n",
    "        print(batch_idx)\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "(61191, 17)\n"
     ]
    }
   ],
   "source": [
    "preds = predict(test_loader)\n",
    "\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# thresh = 0.235\n",
    "\n",
    "df_test = pd.read_csv('sample_submission_v2.csv')\n",
    "\n",
    "outs = dset_train.mlb.inverse_transform(preds > thresh)\n",
    "labelnames = [' '.join(lb) for lb in outs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "subm = pd.DataFrame()\n",
    "subm['image_name'] = df_test.values[:,0]\n",
    "subm['tags'] = labelnames\n",
    "subm.to_csv('submission_resnet18_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>partly_cloudy primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>agriculture clear cultivation primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>cloudy partly_cloudy primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_5</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_6</td>\n",
       "      <td>agriculture clear cultivation habitation primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_7</td>\n",
       "      <td>clear habitation primary road water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_8</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_9</td>\n",
       "      <td>agriculture clear haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_10</td>\n",
       "      <td>partly_cloudy primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test_11</td>\n",
       "      <td>agriculture clear cultivation primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test_12</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test_13</td>\n",
       "      <td>agriculture clear primary road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test_14</td>\n",
       "      <td>agriculture clear cultivation primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>test_15</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>test_16</td>\n",
       "      <td>agriculture clear cultivation habitation prima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>test_17</td>\n",
       "      <td>partly_cloudy primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>test_18</td>\n",
       "      <td>clear haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>test_19</td>\n",
       "      <td>clear primary road water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>test_20</td>\n",
       "      <td>agriculture clear primary road water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>test_21</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>test_22</td>\n",
       "      <td>agriculture clear cultivation habitation prima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>test_23</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>test_24</td>\n",
       "      <td>agriculture partly_cloudy primary road water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>test_25</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>test_26</td>\n",
       "      <td>agriculture habitation partly_cloudy primary road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>test_27</td>\n",
       "      <td>agriculture bare_ground clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>test_28</td>\n",
       "      <td>agriculture habitation partly_cloudy primary road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>test_29</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61161</th>\n",
       "      <td>file_9972</td>\n",
       "      <td>agriculture clear cultivation primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61162</th>\n",
       "      <td>file_9973</td>\n",
       "      <td>agriculture clear cultivation habitation prima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61163</th>\n",
       "      <td>file_9974</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61164</th>\n",
       "      <td>file_9975</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61165</th>\n",
       "      <td>file_9976</td>\n",
       "      <td>agriculture clear cultivation primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61166</th>\n",
       "      <td>file_9977</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61167</th>\n",
       "      <td>file_9978</td>\n",
       "      <td>partly_cloudy primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61168</th>\n",
       "      <td>file_9979</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61169</th>\n",
       "      <td>file_998</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61170</th>\n",
       "      <td>file_9980</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61171</th>\n",
       "      <td>file_9981</td>\n",
       "      <td>agriculture clear cultivation primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61172</th>\n",
       "      <td>file_9982</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61173</th>\n",
       "      <td>file_9983</td>\n",
       "      <td>blooming clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61174</th>\n",
       "      <td>file_9984</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61175</th>\n",
       "      <td>file_9985</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61176</th>\n",
       "      <td>file_9986</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61177</th>\n",
       "      <td>file_9987</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61178</th>\n",
       "      <td>file_9988</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61179</th>\n",
       "      <td>file_9989</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61180</th>\n",
       "      <td>file_999</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61181</th>\n",
       "      <td>file_9990</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61182</th>\n",
       "      <td>file_9991</td>\n",
       "      <td>agriculture clear cultivation primary road water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61183</th>\n",
       "      <td>file_9992</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61184</th>\n",
       "      <td>file_9993</td>\n",
       "      <td>clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61185</th>\n",
       "      <td>file_9994</td>\n",
       "      <td>partly_cloudy primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61186</th>\n",
       "      <td>file_9995</td>\n",
       "      <td>cloudy partly_cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61187</th>\n",
       "      <td>file_9996</td>\n",
       "      <td>clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61188</th>\n",
       "      <td>file_9997</td>\n",
       "      <td>clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61189</th>\n",
       "      <td>file_9998</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61190</th>\n",
       "      <td>file_9999</td>\n",
       "      <td>agriculture clear habitation primary road water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61191 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_name                                               tags\n",
       "0         test_0                                      clear primary\n",
       "1         test_1                                      clear primary\n",
       "2         test_2                              partly_cloudy primary\n",
       "3         test_3              agriculture clear cultivation primary\n",
       "4         test_4                       cloudy partly_cloudy primary\n",
       "5         test_5                                      clear primary\n",
       "6         test_6   agriculture clear cultivation habitation primary\n",
       "7         test_7                clear habitation primary road water\n",
       "8         test_8                                      clear primary\n",
       "9         test_9                     agriculture clear haze primary\n",
       "10       test_10                        partly_cloudy primary water\n",
       "11       test_11              agriculture clear cultivation primary\n",
       "12       test_12                                             cloudy\n",
       "13       test_13                     agriculture clear primary road\n",
       "14       test_14              agriculture clear cultivation primary\n",
       "15       test_15                                      clear primary\n",
       "16       test_16  agriculture clear cultivation habitation prima...\n",
       "17       test_17                              partly_cloudy primary\n",
       "18       test_18                                 clear haze primary\n",
       "19       test_19                           clear primary road water\n",
       "20       test_20               agriculture clear primary road water\n",
       "21       test_21                    agriculture clear primary water\n",
       "22       test_22  agriculture clear cultivation habitation prima...\n",
       "23       test_23                                             cloudy\n",
       "24       test_24       agriculture partly_cloudy primary road water\n",
       "25       test_25                                      clear primary\n",
       "26       test_26  agriculture habitation partly_cloudy primary road\n",
       "27       test_27              agriculture bare_ground clear primary\n",
       "28       test_28  agriculture habitation partly_cloudy primary road\n",
       "29       test_29                                      clear primary\n",
       "...          ...                                                ...\n",
       "61161  file_9972              agriculture clear cultivation primary\n",
       "61162  file_9973  agriculture clear cultivation habitation prima...\n",
       "61163  file_9974                                      clear primary\n",
       "61164  file_9975                                      clear primary\n",
       "61165  file_9976              agriculture clear cultivation primary\n",
       "61166  file_9977                                      clear primary\n",
       "61167  file_9978                              partly_cloudy primary\n",
       "61168  file_9979                                      clear primary\n",
       "61169   file_998                                      clear primary\n",
       "61170  file_9980                                      clear primary\n",
       "61171  file_9981              agriculture clear cultivation primary\n",
       "61172  file_9982          agriculture clear habitation primary road\n",
       "61173  file_9983                             blooming clear primary\n",
       "61174  file_9984                                      clear primary\n",
       "61175  file_9985                                      clear primary\n",
       "61176  file_9986                                      clear primary\n",
       "61177  file_9987          agriculture clear habitation primary road\n",
       "61178  file_9988                                      clear primary\n",
       "61179  file_9989          agriculture clear habitation primary road\n",
       "61180   file_999          agriculture clear habitation primary road\n",
       "61181  file_9990                                      clear primary\n",
       "61182  file_9991   agriculture clear cultivation primary road water\n",
       "61183  file_9992                                      clear primary\n",
       "61184  file_9993                                clear primary water\n",
       "61185  file_9994                        partly_cloudy primary water\n",
       "61186  file_9995                               cloudy partly_cloudy\n",
       "61187  file_9996                                clear primary water\n",
       "61188  file_9997                                clear primary water\n",
       "61189  file_9998                                             cloudy\n",
       "61190  file_9999    agriculture clear habitation primary road water\n",
       "\n",
       "[61191 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
